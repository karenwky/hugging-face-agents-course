{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f7f59de",
   "metadata": {},
   "source": [
    "This is a follow-along notebook of [Agents in LlamaIndex](https://colab.research.google.com/#fileId=https%3A//huggingface.co/agents-course/notebooks/blob/main/unit2/llama-index/agents.ipynb) from [Hugging Face Agents Course](https://huggingface.co/learn/agents-course/unit2/llama-index/agents), with additional trials. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088844c6",
   "metadata": {},
   "source": [
    "# Agents in LlamaIndex\n",
    "> *An Agent is a system that leverages an AI model to interact with its environment to achieve a user-defined objective. It combines reasoning, planning, and action execution (often via external tools) to fulfil tasks.*\n",
    "\n",
    "LlamaIndex supports three main types of reasoning agents:\n",
    "1.  `Function Calling Agents`Â - These work with AI models that can call specific functions.\n",
    "2.  `ReAct Agents`Â - These can work with any AI that does chat or text endpoint and deal with complex reasoning tasks.\n",
    "3.  `Advanced Custom Agents`Â - These use more complex methods to deal with more complex tasks and workflows, like LLMCompiler or Chain-of-Abstraction. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d075f3",
   "metadata": {},
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92c79687",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install llama-index llama-index-vector-stores-chroma llama-index-llms-huggingface-api llama-index-embeddings-huggingface -Uqq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4409d000",
   "metadata": {},
   "source": [
    "## Initialize Agents\n",
    "Let's start by initialising an agent. We will use the basic `AgentWorkflow` class to create an agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ccfa31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.core.agent.workflow import AgentWorkflow, ToolCallResult, AgentStream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b58fdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create calculation functions\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Add two numbers\"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "def subtract(a: int, b: int) -> int:\n",
    "    \"\"\"Subtract two numbers\"\"\"\n",
    "    return a - b\n",
    "\n",
    "\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two numbers\"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "def divide(a: int, b: int) -> int:\n",
    "    \"\"\"Divide two numbers\"\"\"\n",
    "    return a / b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cae739c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "llm = Ollama(model=\"qwen3:8b\", request_timeout=60.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b85515bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize agent\n",
    "agent = AgentWorkflow.from_tools_or_functions(\n",
    "    tools_or_functions=[subtract, multiply, divide, add], \n",
    "    llm=llm, \n",
    "    system_prompt=\"You are a math agent that can add, subtract, multiply, and divide numbers using provided tools.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13494145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Called tool:  add {'a': 2, 'b': 2} => 4\n",
      "\n",
      "Called tool:  multiply {'a': 4, 'b': 2} => 8\n",
      "<think>\n",
      "Okay, let's see. The user asked for (2 + 2) * 2. First, I need to handle the addition inside the parentheses. So I called the add function with a=2 and b=2, which gave 4. Then, I multiplied that result by 2 using the multiply function. The final answer is 8. I should present that clearly.\n",
      "</think>\n",
      "\n",
      "The result of (2 + 2) * 2 is **8**."
     ]
    },
    {
     "data": {
      "text/plain": [
       "AgentOutput(response=ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, additional_kwargs={'tool_calls': []}, blocks=[TextBlock(block_type='text', text=\"<think>\\nOkay, let's see. The user asked for (2 + 2) * 2. First, I need to handle the addition inside the parentheses. So I called the add function with a=2 and b=2, which gave 4. Then, I multiplied that result by 2 using the multiply function. The final answer is 8. I should present that clearly.\\n</think>\\n\\nThe result of (2 + 2) * 2 is **8**.\")]), tool_calls=[ToolCallResult(tool_name='add', tool_kwargs={'a': 2, 'b': 2}, tool_id='add', tool_output=ToolOutput(content='4', tool_name='add', raw_input={'args': (), 'kwargs': {'a': 2, 'b': 2}}, raw_output=4, is_error=False), return_direct=False), ToolCallResult(tool_name='multiply', tool_kwargs={'a': 4, 'b': 2}, tool_id='multiply', tool_output=ToolOutput(content='8', tool_name='multiply', raw_input={'args': (), 'kwargs': {'a': 4, 'b': 2}}, raw_output=8, is_error=False), return_direct=False)], raw={'model': 'qwen3:8b', 'created_at': '2025-05-18T09:26:54.47757Z', 'done': True, 'done_reason': 'stop', 'total_duration': 4873636667, 'load_duration': 16728250, 'prompt_eval_count': 468, 'prompt_eval_duration': 283717750, 'eval_count': 101, 'eval_duration': 4562672041, 'message': Message(role='assistant', content=\"<think>\\nOkay, let's see. The user asked for (2 + 2) * 2. First, I need to handle the addition inside the parentheses. So I called the add function with a=2 and b=2, which gave 4. Then, I multiplied that result by 2 using the multiply function. The final answer is 8. I should present that clearly.\\n</think>\\n\\nThe result of (2 + 2) * 2 is **8**.\", images=None, tool_calls=None), 'usage': {'prompt_tokens': 468, 'completion_tokens': 101, 'total_tokens': 569}}, current_agent_name='Agent')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run agent and print out tool call and thought processes\n",
    "handler = agent.run(\"What is (2 + 2) * 2?\")\n",
    "async for ev in handler.stream_events(): \n",
    "    if isinstance(ev, ToolCallResult): \n",
    "        print(\"\")\n",
    "        print(\"Called tool: \", ev.tool_name, ev.tool_kwargs, \"=>\", ev.tool_output)\n",
    "\n",
    "    elif isinstance(ev, AgentStream):  # show thought process\n",
    "        print(ev.delta, end=\"\", flush=True)\n",
    "\n",
    "resp = await handler\n",
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72bad827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StopEvent()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e84c682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<WorkflowHandler finished result=AgentOutput(r..._name='Agent')>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "handler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6b5913",
   "metadata": {},
   "source": [
    "In a similar fashion, we can pass state and context to the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49413f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.workflow import Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cc58a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up context (agent memory = past chat history)\n",
    "ctx = Context(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a2f72df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<llama_index.core.workflow.context.Context at 0x15dbd3dd0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aeeadcb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentOutput(response=ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, additional_kwargs={'tool_calls': []}, blocks=[TextBlock(block_type='text', text='<think>\\nOkay, the user is asking, \"What was my name again?\" Let me check the conversation history.\\n\\nLooking back, the user first introduced themselves as Karen. The assistant responded with \"Hello, Karen! How can I assist you today?\" Then the user asked, \"What was my name again?\" which seems like they might be confused or testing if I remember.\\n\\nSince the assistant is supposed to remember the user\\'s name from the initial greeting, the answer should be Karen. There\\'s no need to use any of the math functions here because the question is about recalling the user\\'s name, not performing a calculation. The tools provided (add, subtract, multiply, divide) aren\\'t relevant to this query. So, the correct response is to simply state the user\\'s name again.\\n</think>\\n\\nYour name is Karen. ðŸ˜Š')]), tool_calls=[], raw={'model': 'qwen3:8b', 'created_at': '2025-05-18T09:28:50.57393Z', 'done': True, 'done_reason': 'stop', 'total_duration': 7705540917, 'load_duration': 16803708, 'prompt_eval_count': 431, 'prompt_eval_duration': 159370000, 'eval_count': 169, 'eval_duration': 7517781083, 'message': Message(role='assistant', content='<think>\\nOkay, the user is asking, \"What was my name again?\" Let me check the conversation history.\\n\\nLooking back, the user first introduced themselves as Karen. The assistant responded with \"Hello, Karen! How can I assist you today?\" Then the user asked, \"What was my name again?\" which seems like they might be confused or testing if I remember.\\n\\nSince the assistant is supposed to remember the user\\'s name from the initial greeting, the answer should be Karen. There\\'s no need to use any of the math functions here because the question is about recalling the user\\'s name, not performing a calculation. The tools provided (add, subtract, multiply, divide) aren\\'t relevant to this query. So, the correct response is to simply state the user\\'s name again.\\n</think>\\n\\nYour name is Karen. ðŸ˜Š', images=None, tool_calls=None), 'usage': {'prompt_tokens': 431, 'completion_tokens': 169, 'total_tokens': 600}}, current_agent_name='Agent')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add `Context` to run agent\n",
    "response = await agent.run(\"My name is Karen\", ctx=ctx)\n",
    "response = await agent.run(\"What was my name again?\", ctx=ctx)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79b7d746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, the user is asking, \"What was my name again?\" Let me check the conversation history.\n",
      "\n",
      "Looking back, the user first introduced themselves as Karen. The assistant responded with \"Hello, Karen! How can I assist you today?\" Then the user asked, \"What was my name again?\" which seems like they might be confused or testing if I remember.\n",
      "\n",
      "Since the assistant is supposed to remember the user's name from the initial greeting, the answer should be Karen. There's no need to use any of the math functions here because the question is about recalling the user's name, not performing a calculation. The tools provided (add, subtract, multiply, divide) aren't relevant to this query. So, the correct response is to simply state the user's name again.\n",
      "</think>\n",
      "\n",
      "Your name is Karen. ðŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6882de3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctx.is_running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "54154d4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'globals': {'memory': '{\"__is_component\": true, \"value\": {\"chat_store\": {\"store\": {\"chat_history\": [{\"role\": \"user\", \"additional_kwargs\": {}, \"blocks\": [{\"block_type\": \"text\", \"text\": \"My name is Karen\"}]}, {\"role\": \"assistant\", \"additional_kwargs\": {\"tool_calls\": []}, \"blocks\": [{\"block_type\": \"text\", \"text\": \"<think>\\\\nOkay, the user said, \\\\\"My name is Karen.\\\\\" Let me think about how to respond. Since the user introduced themselves, I should greet them politely. The tools provided are for math operations, but this isn\\'t a math question. So I don\\'t need to use any of the functions here. I\\'ll just reply with a friendly welcome message. Something like, \\\\\"Hello, Karen! How can I assist you today?\\\\\" That should cover it without any function calls.\\\\n</think>\\\\n\\\\nHello, Karen! How can I assist you today?\"}]}, {\"role\": \"user\", \"additional_kwargs\": {}, \"blocks\": [{\"block_type\": \"text\", \"text\": \"What was my name again?\"}]}, {\"role\": \"assistant\", \"additional_kwargs\": {\"tool_calls\": []}, \"blocks\": [{\"block_type\": \"text\", \"text\": \"<think>\\\\nOkay, the user is asking, \\\\\"What was my name again?\\\\\" Let me check the conversation history.\\\\n\\\\nLooking back, the user first introduced themselves as Karen. The assistant responded with \\\\\"Hello, Karen! How can I assist you today?\\\\\" Then the user asked, \\\\\"What was my name again?\\\\\" which seems like they might be confused or testing if I remember.\\\\n\\\\nSince the assistant is supposed to remember the user\\'s name from the initial greeting, the answer should be Karen. There\\'s no need to use any of the math functions here because the question is about recalling the user\\'s name, not performing a calculation. The tools provided (add, subtract, multiply, divide) aren\\'t relevant to this query. So, the correct response is to simply state the user\\'s name again.\\\\n</think>\\\\n\\\\nYour name is Karen. \\\\ud83d\\\\ude0a\"}]}]}, \"class_name\": \"SimpleChatStore\"}, \"chat_store_key\": \"chat_history\", \"token_limit\": 2925, \"class_name\": \"ChatMemoryBuffer\"}, \"qualified_name\": \"llama_index.core.memory.chat_memory_buffer.ChatMemoryBuffer\"}',\n",
       "  'agents': '[\"Agent\"]',\n",
       "  'can_handoff_to': '{\"Agent\": null}',\n",
       "  'state': '{}',\n",
       "  'current_agent_name': '\"Agent\"',\n",
       "  'handoff_output_prompt': '\"Agent {to_agent} is now handling the request due to the following reason: {reason}.\\\\nPlease continue with the current request.\"',\n",
       "  'formatted_input_with_state': 'false',\n",
       "  'user_msg_str': '\"What was my name again?\"',\n",
       "  'scratchpad': '[]',\n",
       "  'current_tool_calls': '[]'},\n",
       " 'streaming_queue': '[\"{\\\\\"__is_pydantic\\\\\": true, \\\\\"value\\\\\": {\\\\\"input\\\\\": [{\\\\\"role\\\\\": \\\\\"system\\\\\", \\\\\"additional_kwargs\\\\\": {}, \\\\\"blocks\\\\\": [{\\\\\"block_type\\\\\": \\\\\"text\\\\\", \\\\\"text\\\\\": \\\\\"You are a math agent that can add, subtract, multiply, and divide numbers using provided tools.\\\\\"}]}, {\\\\\"role\\\\\": \\\\\"user\\\\\", \\\\\"additional_kwargs\\\\\": {}, \\\\\"blocks\\\\\": [{\\\\\"block_type\\\\\": \\\\\"text\\\\\", \\\\\"text\\\\\": \\\\\"My name is Karen\\\\\"}]}], \\\\\"current_agent_name\\\\\": \\\\\"Agent\\\\\"}, \\\\\"qualified_name\\\\\": \\\\\"llama_index.core.agent.workflow.workflow_events.AgentInput\\\\\"}\", \"{\\\\\"__is_pydantic\\\\\": true, \\\\\"value\\\\\": {\\\\\"delta\\\\\": \\\\\"<think>\\\\\\\\nOkay, the user said, \\\\\\\\\\\\\"My name is Karen.\\\\\\\\\\\\\" Let me think about how to respond. Since the user introduced themselves, I should greet them politely. The tools provided are for math operations, but this isn\\'t a math question. So I don\\'t need to use any of the functions here. I\\'ll just reply with a friendly welcome message. Something like, \\\\\\\\\\\\\"Hello, Karen! How can I assist you today?\\\\\\\\\\\\\" That should cover it without any function calls.\\\\\\\\n</think>\\\\\\\\n\\\\\\\\nHello, Karen! How can I assist you today?\\\\\", \\\\\"response\\\\\": \\\\\"<think>\\\\\\\\nOkay, the user said, \\\\\\\\\\\\\"My name is Karen.\\\\\\\\\\\\\" Let me think about how to respond. Since the user introduced themselves, I should greet them politely. The tools provided are for math operations, but this isn\\'t a math question. So I don\\'t need to use any of the functions here. I\\'ll just reply with a friendly welcome message. Something like, \\\\\\\\\\\\\"Hello, Karen! How can I assist you today?\\\\\\\\\\\\\" That should cover it without any function calls.\\\\\\\\n</think>\\\\\\\\n\\\\\\\\nHello, Karen! How can I assist you today?\\\\\", \\\\\"current_agent_name\\\\\": \\\\\"Agent\\\\\", \\\\\"tool_calls\\\\\": [], \\\\\"raw\\\\\": {\\\\\"model\\\\\": \\\\\"qwen3:8b\\\\\", \\\\\"created_at\\\\\": \\\\\"2025-05-18T09:28:42.817518Z\\\\\", \\\\\"done\\\\\": true, \\\\\"done_reason\\\\\": \\\\\"stop\\\\\", \\\\\"total_duration\\\\\": 7226712042, \\\\\"load_duration\\\\\": 36424208, \\\\\"prompt_eval_count\\\\\": 404, \\\\\"prompt_eval_duration\\\\\": 2367840334, \\\\\"eval_count\\\\\": 111, \\\\\"eval_duration\\\\\": 4809309458, \\\\\"message\\\\\": {\\\\\"role\\\\\": \\\\\"assistant\\\\\", \\\\\"content\\\\\": \\\\\"<think>\\\\\\\\nOkay, the user said, \\\\\\\\\\\\\"My name is Karen.\\\\\\\\\\\\\" Let me think about how to respond. Since the user introduced themselves, I should greet them politely. The tools provided are for math operations, but this isn\\'t a math question. So I don\\'t need to use any of the functions here. I\\'ll just reply with a friendly welcome message. Something like, \\\\\\\\\\\\\"Hello, Karen! How can I assist you today?\\\\\\\\\\\\\" That should cover it without any function calls.\\\\\\\\n</think>\\\\\\\\n\\\\\\\\nHello, Karen! How can I assist you today?\\\\\", \\\\\"images\\\\\": null, \\\\\"tool_calls\\\\\": null}, \\\\\"usage\\\\\": {\\\\\"prompt_tokens\\\\\": 404, \\\\\"completion_tokens\\\\\": 111, \\\\\"total_tokens\\\\\": 515}}}, \\\\\"qualified_name\\\\\": \\\\\"llama_index.core.agent.workflow.workflow_events.AgentStream\\\\\"}\", \"{\\\\\"__is_pydantic\\\\\": true, \\\\\"value\\\\\": {\\\\\"response\\\\\": {\\\\\"role\\\\\": \\\\\"assistant\\\\\", \\\\\"additional_kwargs\\\\\": {\\\\\"tool_calls\\\\\": []}, \\\\\"blocks\\\\\": [{\\\\\"block_type\\\\\": \\\\\"text\\\\\", \\\\\"text\\\\\": \\\\\"<think>\\\\\\\\nOkay, the user said, \\\\\\\\\\\\\"My name is Karen.\\\\\\\\\\\\\" Let me think about how to respond. Since the user introduced themselves, I should greet them politely. The tools provided are for math operations, but this isn\\'t a math question. So I don\\'t need to use any of the functions here. I\\'ll just reply with a friendly welcome message. Something like, \\\\\\\\\\\\\"Hello, Karen! How can I assist you today?\\\\\\\\\\\\\" That should cover it without any function calls.\\\\\\\\n</think>\\\\\\\\n\\\\\\\\nHello, Karen! How can I assist you today?\\\\\"}]}, \\\\\"tool_calls\\\\\": [], \\\\\"raw\\\\\": {\\\\\"model\\\\\": \\\\\"qwen3:8b\\\\\", \\\\\"created_at\\\\\": \\\\\"2025-05-18T09:28:42.817518Z\\\\\", \\\\\"done\\\\\": true, \\\\\"done_reason\\\\\": \\\\\"stop\\\\\", \\\\\"total_duration\\\\\": 7226712042, \\\\\"load_duration\\\\\": 36424208, \\\\\"prompt_eval_count\\\\\": 404, \\\\\"prompt_eval_duration\\\\\": 2367840334, \\\\\"eval_count\\\\\": 111, \\\\\"eval_duration\\\\\": 4809309458, \\\\\"message\\\\\": {\\\\\"role\\\\\": \\\\\"assistant\\\\\", \\\\\"content\\\\\": \\\\\"<think>\\\\\\\\nOkay, the user said, \\\\\\\\\\\\\"My name is Karen.\\\\\\\\\\\\\" Let me think about how to respond. Since the user introduced themselves, I should greet them politely. The tools provided are for math operations, but this isn\\'t a math question. So I don\\'t need to use any of the functions here. I\\'ll just reply with a friendly welcome message. Something like, \\\\\\\\\\\\\"Hello, Karen! How can I assist you today?\\\\\\\\\\\\\" That should cover it without any function calls.\\\\\\\\n</think>\\\\\\\\n\\\\\\\\nHello, Karen! How can I assist you today?\\\\\", \\\\\"images\\\\\": null, \\\\\"tool_calls\\\\\": null}, \\\\\"usage\\\\\": {\\\\\"prompt_tokens\\\\\": 404, \\\\\"completion_tokens\\\\\": 111, \\\\\"total_tokens\\\\\": 515}}, \\\\\"current_agent_name\\\\\": \\\\\"Agent\\\\\"}, \\\\\"qualified_name\\\\\": \\\\\"llama_index.core.agent.workflow.workflow_events.AgentOutput\\\\\"}\", \"{\\\\\"__is_pydantic\\\\\": true, \\\\\"value\\\\\": {}, \\\\\"qualified_name\\\\\": \\\\\"llama_index.core.workflow.events.StopEvent\\\\\"}\", \"{\\\\\"__is_pydantic\\\\\": true, \\\\\"value\\\\\": {\\\\\"input\\\\\": [{\\\\\"role\\\\\": \\\\\"system\\\\\", \\\\\"additional_kwargs\\\\\": {}, \\\\\"blocks\\\\\": [{\\\\\"block_type\\\\\": \\\\\"text\\\\\", \\\\\"text\\\\\": \\\\\"You are a math agent that can add, subtract, multiply, and divide numbers using provided tools.\\\\\"}]}, {\\\\\"role\\\\\": \\\\\"user\\\\\", \\\\\"additional_kwargs\\\\\": {}, \\\\\"blocks\\\\\": [{\\\\\"block_type\\\\\": \\\\\"text\\\\\", \\\\\"text\\\\\": \\\\\"My name is Karen\\\\\"}]}, {\\\\\"role\\\\\": \\\\\"assistant\\\\\", \\\\\"additional_kwargs\\\\\": {\\\\\"tool_calls\\\\\": []}, \\\\\"blocks\\\\\": [{\\\\\"block_type\\\\\": \\\\\"text\\\\\", \\\\\"text\\\\\": \\\\\"<think>\\\\\\\\nOkay, the user said, \\\\\\\\\\\\\"My name is Karen.\\\\\\\\\\\\\" Let me think about how to respond. Since the user introduced themselves, I should greet them politely. The tools provided are for math operations, but this isn\\'t a math question. So I don\\'t need to use any of the functions here. I\\'ll just reply with a friendly welcome message. Something like, \\\\\\\\\\\\\"Hello, Karen! How can I assist you today?\\\\\\\\\\\\\" That should cover it without any function calls.\\\\\\\\n</think>\\\\\\\\n\\\\\\\\nHello, Karen! How can I assist you today?\\\\\"}]}, {\\\\\"role\\\\\": \\\\\"user\\\\\", \\\\\"additional_kwargs\\\\\": {}, \\\\\"blocks\\\\\": [{\\\\\"block_type\\\\\": \\\\\"text\\\\\", \\\\\"text\\\\\": \\\\\"What was my name again?\\\\\"}]}], \\\\\"current_agent_name\\\\\": \\\\\"Agent\\\\\"}, \\\\\"qualified_name\\\\\": \\\\\"llama_index.core.agent.workflow.workflow_events.AgentInput\\\\\"}\", \"{\\\\\"__is_pydantic\\\\\": true, \\\\\"value\\\\\": {\\\\\"delta\\\\\": \\\\\"<think>\\\\\\\\nOkay, the user is asking, \\\\\\\\\\\\\"What was my name again?\\\\\\\\\\\\\" Let me check the conversation history.\\\\\\\\n\\\\\\\\nLooking back, the user first introduced themselves as Karen. The assistant responded with \\\\\\\\\\\\\"Hello, Karen! How can I assist you today?\\\\\\\\\\\\\" Then the user asked, \\\\\\\\\\\\\"What was my name again?\\\\\\\\\\\\\" which seems like they might be confused or testing if I remember.\\\\\\\\n\\\\\\\\nSince the assistant is supposed to remember the user\\'s name from the initial greeting, the answer should be Karen. There\\'s no need to use any of the math functions here because the question is about recalling the user\\'s name, not performing a calculation. The tools provided (add, subtract, multiply, divide) aren\\'t relevant to this query. So, the correct response is to simply state the user\\'s name again.\\\\\\\\n</think>\\\\\\\\n\\\\\\\\nYour name is Karen. \\\\\\\\ud83d\\\\\\\\ude0a\\\\\", \\\\\"response\\\\\": \\\\\"<think>\\\\\\\\nOkay, the user is asking, \\\\\\\\\\\\\"What was my name again?\\\\\\\\\\\\\" Let me check the conversation history.\\\\\\\\n\\\\\\\\nLooking back, the user first introduced themselves as Karen. The assistant responded with \\\\\\\\\\\\\"Hello, Karen! How can I assist you today?\\\\\\\\\\\\\" Then the user asked, \\\\\\\\\\\\\"What was my name again?\\\\\\\\\\\\\" which seems like they might be confused or testing if I remember.\\\\\\\\n\\\\\\\\nSince the assistant is supposed to remember the user\\'s name from the initial greeting, the answer should be Karen. There\\'s no need to use any of the math functions here because the question is about recalling the user\\'s name, not performing a calculation. The tools provided (add, subtract, multiply, divide) aren\\'t relevant to this query. So, the correct response is to simply state the user\\'s name again.\\\\\\\\n</think>\\\\\\\\n\\\\\\\\nYour name is Karen. \\\\\\\\ud83d\\\\\\\\ude0a\\\\\", \\\\\"current_agent_name\\\\\": \\\\\"Agent\\\\\", \\\\\"tool_calls\\\\\": [], \\\\\"raw\\\\\": {\\\\\"model\\\\\": \\\\\"qwen3:8b\\\\\", \\\\\"created_at\\\\\": \\\\\"2025-05-18T09:28:50.57393Z\\\\\", \\\\\"done\\\\\": true, \\\\\"done_reason\\\\\": \\\\\"stop\\\\\", \\\\\"total_duration\\\\\": 7705540917, \\\\\"load_duration\\\\\": 16803708, \\\\\"prompt_eval_count\\\\\": 431, \\\\\"prompt_eval_duration\\\\\": 159370000, \\\\\"eval_count\\\\\": 169, \\\\\"eval_duration\\\\\": 7517781083, \\\\\"message\\\\\": {\\\\\"role\\\\\": \\\\\"assistant\\\\\", \\\\\"content\\\\\": \\\\\"<think>\\\\\\\\nOkay, the user is asking, \\\\\\\\\\\\\"What was my name again?\\\\\\\\\\\\\" Let me check the conversation history.\\\\\\\\n\\\\\\\\nLooking back, the user first introduced themselves as Karen. The assistant responded with \\\\\\\\\\\\\"Hello, Karen! How can I assist you today?\\\\\\\\\\\\\" Then the user asked, \\\\\\\\\\\\\"What was my name again?\\\\\\\\\\\\\" which seems like they might be confused or testing if I remember.\\\\\\\\n\\\\\\\\nSince the assistant is supposed to remember the user\\'s name from the initial greeting, the answer should be Karen. There\\'s no need to use any of the math functions here because the question is about recalling the user\\'s name, not performing a calculation. The tools provided (add, subtract, multiply, divide) aren\\'t relevant to this query. So, the correct response is to simply state the user\\'s name again.\\\\\\\\n</think>\\\\\\\\n\\\\\\\\nYour name is Karen. \\\\\\\\ud83d\\\\\\\\ude0a\\\\\", \\\\\"images\\\\\": null, \\\\\"tool_calls\\\\\": null}, \\\\\"usage\\\\\": {\\\\\"prompt_tokens\\\\\": 431, \\\\\"completion_tokens\\\\\": 169, \\\\\"total_tokens\\\\\": 600}}}, \\\\\"qualified_name\\\\\": \\\\\"llama_index.core.agent.workflow.workflow_events.AgentStream\\\\\"}\", \"{\\\\\"__is_pydantic\\\\\": true, \\\\\"value\\\\\": {\\\\\"response\\\\\": {\\\\\"role\\\\\": \\\\\"assistant\\\\\", \\\\\"additional_kwargs\\\\\": {\\\\\"tool_calls\\\\\": []}, \\\\\"blocks\\\\\": [{\\\\\"block_type\\\\\": \\\\\"text\\\\\", \\\\\"text\\\\\": \\\\\"<think>\\\\\\\\nOkay, the user is asking, \\\\\\\\\\\\\"What was my name again?\\\\\\\\\\\\\" Let me check the conversation history.\\\\\\\\n\\\\\\\\nLooking back, the user first introduced themselves as Karen. The assistant responded with \\\\\\\\\\\\\"Hello, Karen! How can I assist you today?\\\\\\\\\\\\\" Then the user asked, \\\\\\\\\\\\\"What was my name again?\\\\\\\\\\\\\" which seems like they might be confused or testing if I remember.\\\\\\\\n\\\\\\\\nSince the assistant is supposed to remember the user\\'s name from the initial greeting, the answer should be Karen. There\\'s no need to use any of the math functions here because the question is about recalling the user\\'s name, not performing a calculation. The tools provided (add, subtract, multiply, divide) aren\\'t relevant to this query. So, the correct response is to simply state the user\\'s name again.\\\\\\\\n</think>\\\\\\\\n\\\\\\\\nYour name is Karen. \\\\\\\\ud83d\\\\\\\\ude0a\\\\\"}]}, \\\\\"tool_calls\\\\\": [], \\\\\"raw\\\\\": {\\\\\"model\\\\\": \\\\\"qwen3:8b\\\\\", \\\\\"created_at\\\\\": \\\\\"2025-05-18T09:28:50.57393Z\\\\\", \\\\\"done\\\\\": true, \\\\\"done_reason\\\\\": \\\\\"stop\\\\\", \\\\\"total_duration\\\\\": 7705540917, \\\\\"load_duration\\\\\": 16803708, \\\\\"prompt_eval_count\\\\\": 431, \\\\\"prompt_eval_duration\\\\\": 159370000, \\\\\"eval_count\\\\\": 169, \\\\\"eval_duration\\\\\": 7517781083, \\\\\"message\\\\\": {\\\\\"role\\\\\": \\\\\"assistant\\\\\", \\\\\"content\\\\\": \\\\\"<think>\\\\\\\\nOkay, the user is asking, \\\\\\\\\\\\\"What was my name again?\\\\\\\\\\\\\" Let me check the conversation history.\\\\\\\\n\\\\\\\\nLooking back, the user first introduced themselves as Karen. The assistant responded with \\\\\\\\\\\\\"Hello, Karen! How can I assist you today?\\\\\\\\\\\\\" Then the user asked, \\\\\\\\\\\\\"What was my name again?\\\\\\\\\\\\\" which seems like they might be confused or testing if I remember.\\\\\\\\n\\\\\\\\nSince the assistant is supposed to remember the user\\'s name from the initial greeting, the answer should be Karen. There\\'s no need to use any of the math functions here because the question is about recalling the user\\'s name, not performing a calculation. The tools provided (add, subtract, multiply, divide) aren\\'t relevant to this query. So, the correct response is to simply state the user\\'s name again.\\\\\\\\n</think>\\\\\\\\n\\\\\\\\nYour name is Karen. \\\\\\\\ud83d\\\\\\\\ude0a\\\\\", \\\\\"images\\\\\": null, \\\\\"tool_calls\\\\\": null}, \\\\\"usage\\\\\": {\\\\\"prompt_tokens\\\\\": 431, \\\\\"completion_tokens\\\\\": 169, \\\\\"total_tokens\\\\\": 600}}, \\\\\"current_agent_name\\\\\": \\\\\"Agent\\\\\"}, \\\\\"qualified_name\\\\\": \\\\\"llama_index.core.agent.workflow.workflow_events.AgentOutput\\\\\"}\", \"{\\\\\"__is_pydantic\\\\\": true, \\\\\"value\\\\\": {}, \\\\\"qualified_name\\\\\": \\\\\"llama_index.core.workflow.events.StopEvent\\\\\"}\"]',\n",
       " 'queues': {'_done': '[]',\n",
       "  'aggregate_tool_results': '[]',\n",
       "  'call_tool': '[]',\n",
       "  'init_run': '[]',\n",
       "  'parse_agent_output': '[]',\n",
       "  'run_agent_step': '[]',\n",
       "  'setup_agent': '[]'},\n",
       " 'stepwise': False,\n",
       " 'event_buffers': {},\n",
       " 'in_progress': {'init_run': [],\n",
       "  'setup_agent': [],\n",
       "  'run_agent_step': [],\n",
       "  'parse_agent_output': [],\n",
       "  '_done': []},\n",
       " 'accepted_events': [('init_run', 'AgentWorkflowStartEvent'),\n",
       "  ('setup_agent', 'AgentInput'),\n",
       "  ('run_agent_step', 'AgentSetup'),\n",
       "  ('parse_agent_output', 'AgentOutput'),\n",
       "  ('init_run', 'AgentWorkflowStartEvent'),\n",
       "  ('setup_agent', 'AgentInput'),\n",
       "  ('run_agent_step', 'AgentSetup'),\n",
       "  ('parse_agent_output', 'AgentOutput')],\n",
       " 'broker_log': ['{\"__is_pydantic\": true, \"value\": {\"user_msg\": \"My name is Karen\", \"chat_history\": null}, \"qualified_name\": \"llama_index.core.agent.workflow.multi_agent_workflow.AgentWorkflowStartEvent\"}',\n",
       "  '{\"__is_pydantic\": true, \"value\": {\"input\": [{\"role\": \"user\", \"additional_kwargs\": {}, \"blocks\": [{\"block_type\": \"text\", \"text\": \"My name is Karen\"}]}], \"current_agent_name\": \"Agent\"}, \"qualified_name\": \"llama_index.core.agent.workflow.workflow_events.AgentInput\"}',\n",
       "  '{\"__is_pydantic\": true, \"value\": {\"input\": [{\"role\": \"system\", \"additional_kwargs\": {}, \"blocks\": [{\"block_type\": \"text\", \"text\": \"You are a math agent that can add, subtract, multiply, and divide numbers using provided tools.\"}]}, {\"role\": \"user\", \"additional_kwargs\": {}, \"blocks\": [{\"block_type\": \"text\", \"text\": \"My name is Karen\"}]}], \"current_agent_name\": \"Agent\"}, \"qualified_name\": \"llama_index.core.agent.workflow.workflow_events.AgentSetup\"}',\n",
       "  '{\"__is_pydantic\": true, \"value\": {\"response\": {\"role\": \"assistant\", \"additional_kwargs\": {\"tool_calls\": []}, \"blocks\": [{\"block_type\": \"text\", \"text\": \"<think>\\\\nOkay, the user said, \\\\\"My name is Karen.\\\\\" Let me think about how to respond. Since the user introduced themselves, I should greet them politely. The tools provided are for math operations, but this isn\\'t a math question. So I don\\'t need to use any of the functions here. I\\'ll just reply with a friendly welcome message. Something like, \\\\\"Hello, Karen! How can I assist you today?\\\\\" That should cover it without any function calls.\\\\n</think>\\\\n\\\\nHello, Karen! How can I assist you today?\"}]}, \"tool_calls\": [], \"raw\": {\"model\": \"qwen3:8b\", \"created_at\": \"2025-05-18T09:28:42.817518Z\", \"done\": true, \"done_reason\": \"stop\", \"total_duration\": 7226712042, \"load_duration\": 36424208, \"prompt_eval_count\": 404, \"prompt_eval_duration\": 2367840334, \"eval_count\": 111, \"eval_duration\": 4809309458, \"message\": {\"role\": \"assistant\", \"content\": \"<think>\\\\nOkay, the user said, \\\\\"My name is Karen.\\\\\" Let me think about how to respond. Since the user introduced themselves, I should greet them politely. The tools provided are for math operations, but this isn\\'t a math question. So I don\\'t need to use any of the functions here. I\\'ll just reply with a friendly welcome message. Something like, \\\\\"Hello, Karen! How can I assist you today?\\\\\" That should cover it without any function calls.\\\\n</think>\\\\n\\\\nHello, Karen! How can I assist you today?\", \"images\": null, \"tool_calls\": null}, \"usage\": {\"prompt_tokens\": 404, \"completion_tokens\": 111, \"total_tokens\": 515}}, \"current_agent_name\": \"Agent\"}, \"qualified_name\": \"llama_index.core.agent.workflow.workflow_events.AgentOutput\"}',\n",
       "  '{\"__is_pydantic\": true, \"value\": {}, \"qualified_name\": \"llama_index.core.workflow.events.StopEvent\"}',\n",
       "  '{\"__is_pydantic\": true, \"value\": {\"user_msg\": \"What was my name again?\", \"chat_history\": null}, \"qualified_name\": \"llama_index.core.agent.workflow.multi_agent_workflow.AgentWorkflowStartEvent\"}',\n",
       "  '{\"__is_pydantic\": true, \"value\": {\"input\": [{\"role\": \"user\", \"additional_kwargs\": {}, \"blocks\": [{\"block_type\": \"text\", \"text\": \"My name is Karen\"}]}, {\"role\": \"assistant\", \"additional_kwargs\": {\"tool_calls\": []}, \"blocks\": [{\"block_type\": \"text\", \"text\": \"<think>\\\\nOkay, the user said, \\\\\"My name is Karen.\\\\\" Let me think about how to respond. Since the user introduced themselves, I should greet them politely. The tools provided are for math operations, but this isn\\'t a math question. So I don\\'t need to use any of the functions here. I\\'ll just reply with a friendly welcome message. Something like, \\\\\"Hello, Karen! How can I assist you today?\\\\\" That should cover it without any function calls.\\\\n</think>\\\\n\\\\nHello, Karen! How can I assist you today?\"}]}, {\"role\": \"user\", \"additional_kwargs\": {}, \"blocks\": [{\"block_type\": \"text\", \"text\": \"What was my name again?\"}]}], \"current_agent_name\": \"Agent\"}, \"qualified_name\": \"llama_index.core.agent.workflow.workflow_events.AgentInput\"}',\n",
       "  '{\"__is_pydantic\": true, \"value\": {\"input\": [{\"role\": \"system\", \"additional_kwargs\": {}, \"blocks\": [{\"block_type\": \"text\", \"text\": \"You are a math agent that can add, subtract, multiply, and divide numbers using provided tools.\"}]}, {\"role\": \"user\", \"additional_kwargs\": {}, \"blocks\": [{\"block_type\": \"text\", \"text\": \"My name is Karen\"}]}, {\"role\": \"assistant\", \"additional_kwargs\": {\"tool_calls\": []}, \"blocks\": [{\"block_type\": \"text\", \"text\": \"<think>\\\\nOkay, the user said, \\\\\"My name is Karen.\\\\\" Let me think about how to respond. Since the user introduced themselves, I should greet them politely. The tools provided are for math operations, but this isn\\'t a math question. So I don\\'t need to use any of the functions here. I\\'ll just reply with a friendly welcome message. Something like, \\\\\"Hello, Karen! How can I assist you today?\\\\\" That should cover it without any function calls.\\\\n</think>\\\\n\\\\nHello, Karen! How can I assist you today?\"}]}, {\"role\": \"user\", \"additional_kwargs\": {}, \"blocks\": [{\"block_type\": \"text\", \"text\": \"What was my name again?\"}]}], \"current_agent_name\": \"Agent\"}, \"qualified_name\": \"llama_index.core.agent.workflow.workflow_events.AgentSetup\"}',\n",
       "  '{\"__is_pydantic\": true, \"value\": {\"response\": {\"role\": \"assistant\", \"additional_kwargs\": {\"tool_calls\": []}, \"blocks\": [{\"block_type\": \"text\", \"text\": \"<think>\\\\nOkay, the user is asking, \\\\\"What was my name again?\\\\\" Let me check the conversation history.\\\\n\\\\nLooking back, the user first introduced themselves as Karen. The assistant responded with \\\\\"Hello, Karen! How can I assist you today?\\\\\" Then the user asked, \\\\\"What was my name again?\\\\\" which seems like they might be confused or testing if I remember.\\\\n\\\\nSince the assistant is supposed to remember the user\\'s name from the initial greeting, the answer should be Karen. There\\'s no need to use any of the math functions here because the question is about recalling the user\\'s name, not performing a calculation. The tools provided (add, subtract, multiply, divide) aren\\'t relevant to this query. So, the correct response is to simply state the user\\'s name again.\\\\n</think>\\\\n\\\\nYour name is Karen. \\\\ud83d\\\\ude0a\"}]}, \"tool_calls\": [], \"raw\": {\"model\": \"qwen3:8b\", \"created_at\": \"2025-05-18T09:28:50.57393Z\", \"done\": true, \"done_reason\": \"stop\", \"total_duration\": 7705540917, \"load_duration\": 16803708, \"prompt_eval_count\": 431, \"prompt_eval_duration\": 159370000, \"eval_count\": 169, \"eval_duration\": 7517781083, \"message\": {\"role\": \"assistant\", \"content\": \"<think>\\\\nOkay, the user is asking, \\\\\"What was my name again?\\\\\" Let me check the conversation history.\\\\n\\\\nLooking back, the user first introduced themselves as Karen. The assistant responded with \\\\\"Hello, Karen! How can I assist you today?\\\\\" Then the user asked, \\\\\"What was my name again?\\\\\" which seems like they might be confused or testing if I remember.\\\\n\\\\nSince the assistant is supposed to remember the user\\'s name from the initial greeting, the answer should be Karen. There\\'s no need to use any of the math functions here because the question is about recalling the user\\'s name, not performing a calculation. The tools provided (add, subtract, multiply, divide) aren\\'t relevant to this query. So, the correct response is to simply state the user\\'s name again.\\\\n</think>\\\\n\\\\nYour name is Karen. \\\\ud83d\\\\ude0a\", \"images\": null, \"tool_calls\": null}, \"usage\": {\"prompt_tokens\": 431, \"completion_tokens\": 169, \"total_tokens\": 600}}, \"current_agent_name\": \"Agent\"}, \"qualified_name\": \"llama_index.core.agent.workflow.workflow_events.AgentOutput\"}',\n",
       "  '{\"__is_pydantic\": true, \"value\": {}, \"qualified_name\": \"llama_index.core.workflow.events.StopEvent\"}'],\n",
       " 'is_running': False}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctx.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09b318f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tool functions\n",
    "def bmi_status(weight: float, height: float) -> str:\n",
    "    \"\"\"\n",
    "    This tool caculates the Body Mass Index (BMI) based on weight in kilograms and height in meters.\n",
    "    It returns a BMI category (Underweight, Normal, Overweight, or Obese).\n",
    "    \"\"\"\n",
    "    bmi = weight / (height ** 2)\n",
    "\n",
    "    if bmi <= 18.5:\n",
    "        return \"Underweight\"\n",
    "    elif bmi <= 25.0:\n",
    "        return \"Normal\"\n",
    "    elif bmi <= 30.0:\n",
    "        return \"Overweight\"\n",
    "    else:\n",
    "        return \"Obese\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1952f007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synthetic patient data\n",
    "data = [\n",
    "    {\"name\": \"Alice\", \"weight\": 50, \"height\": 1.65},\n",
    "    {\"name\": \"Bob\", \"weight\": 85, \"height\": 1.75},\n",
    "    {\"name\": \"Charlie\", \"weight\": 70, \"height\": 1.80},\n",
    "    {\"name\": \"Diana\", \"weight\": 45, \"height\": 1.60},\n",
    "    {\"name\": \"Ethan\", \"weight\": 100, \"height\": 1.70},\n",
    "    {\"name\": \"Fiona\", \"weight\": 60, \"height\": 1.72},\n",
    "    {\"name\": \"George\", \"weight\": 120, \"height\": 1.85},\n",
    "    {\"name\": \"Hannah\", \"weight\": 55, \"height\": 1.68},\n",
    "    {\"name\": \"Ian\", \"weight\": 90, \"height\": 1.78},\n",
    "    {\"name\": \"Julia\", \"weight\": 40, \"height\": 1.55}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a41b24c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize agent\n",
    "agent = AgentWorkflow.from_tools_or_functions(\n",
    "    tools_or_functions=[bmi_status], \n",
    "    llm=llm, \n",
    "    system_prompt=\"You are a clinic assistant analysing patient data. You help calculate BMI and return health status using provided tools.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c593afcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'handoff_prompt': PromptTemplate(metadata={'prompt_type': <PromptType.CUSTOM: 'custom'>}, template_vars=['agent_info'], kwargs={}, output_parser=None, template_var_mappings=None, function_mappings=None, template=\"Useful for handing off to another agent.\\nIf you are currently not equipped to handle the user's request, or another agent is better suited to handle the request, please hand off to the appropriate agent.\\n\\nCurrently available agents:\\n{agent_info}\\n\"),\n",
       " 'handoff_output_prompt': PromptTemplate(metadata={'prompt_type': <PromptType.CUSTOM: 'custom'>}, template_vars=['to_agent', 'reason'], kwargs={}, output_parser=None, template_var_mappings=None, function_mappings=None, template='Agent {to_agent} is now handling the request due to the following reason: {reason}.\\nPlease continue with the current request.'),\n",
       " 'state_prompt': PromptTemplate(metadata={'prompt_type': <PromptType.CUSTOM: 'custom'>}, template_vars=['state', 'msg'], kwargs={}, output_parser=None, template_var_mappings=None, function_mappings=None, template='Current state:\\n{state}\\n\\nCurrent message:\\n{msg}\\n')}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.get_prompts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7cfecac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(metadata={'prompt_type': <PromptType.CUSTOM: 'custom'>}, template_vars=['state', 'msg'], kwargs={}, output_parser=None, template_var_mappings=None, function_mappings=None, template='Current state:\\n{state}\\n\\nCurrent message:\\n{msg}\\n')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.state_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6b5b49bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(metadata={'prompt_type': <PromptType.CUSTOM: 'custom'>}, template_vars=['to_agent', 'reason'], kwargs={}, output_parser=None, template_var_mappings=None, function_mappings=None, template='Agent {to_agent} is now handling the request due to the following reason: {reason}.\\nPlease continue with the current request.')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.handoff_output_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "96bda8a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method AgentWorkflow.get_tools of <llama_index.core.agent.workflow.multi_agent_workflow.AgentWorkflow object at 0x15d98fad0>>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.get_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de2b85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust LLM timeout\n",
    "# DEFAULT_REQUEST_TIMEOUT = 30.0\n",
    "llm = Ollama(model=\"qwen3:8b\", request_timeout=600.0)\n",
    "\n",
    "# Initialize agent\n",
    "agent = AgentWorkflow.from_tools_or_functions(\n",
    "    tools_or_functions=[bmi_status], \n",
    "    llm=llm, \n",
    "    system_prompt=\"You are a clinic assistant analysing patient data. You help calculate BMI and return health status using provided tools.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "014ad0b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Called tool:  bmi_status {'height': 1.65, 'weight': 50} => Underweight\n",
      "\n",
      "Called tool:  bmi_status {'height': 1.75, 'weight': 85} => Overweight\n",
      "\n",
      "Called tool:  bmi_status {'height': 1.8, 'weight': 70} => Normal\n",
      "\n",
      "Called tool:  bmi_status {'height': 1.6, 'weight': 45} => Underweight\n",
      "\n",
      "Called tool:  bmi_status {'height': 1.7, 'weight': 100} => Obese\n",
      "\n",
      "Called tool:  bmi_status {'height': 1.72, 'weight': 60} => Normal\n",
      "\n",
      "Called tool:  bmi_status {'height': 1.85, 'weight': 120} => Obese\n",
      "\n",
      "Called tool:  bmi_status {'height': 1.68, 'weight': 55} => Normal\n",
      "\n",
      "Called tool:  bmi_status {'height': 1.78, 'weight': 90} => Overweight\n",
      "\n",
      "Called tool:  bmi_status {'height': 1.55, 'weight': 40} => Underweight\n",
      "<think>\n",
      "Okay, I need to process the patient data and calculate their BMI status. Let me start by recalling the BMI categories. BMI is calculated as weight divided by height squared. The categories are Underweight (BMI < 18.5), Normal (18.5â€“24.9), Overweight (25â€“29.9), and Obese (â‰¥30).\n",
      "\n",
      "Looking at the patients:\n",
      "\n",
      "1. **Alice**: Weight 50 kg, height 1.65 m. Let me calculate BMI: 50/(1.65^2) â‰ˆ 50/2.72 â‰ˆ 18.4. So Underweight.\n",
      "2. **Bob**: 85 kg, 1.75 m. 85/(1.75^2) â‰ˆ 85/3.06 â‰ˆ 27.7. Overweight.\n",
      "3. **Charlie**: 70 kg, 1.8 m. 70/(1.8^2) â‰ˆ 70/3.24 â‰ˆ 21.6. Normal.\n",
      "4. **Diana**: 45 kg, 1.6 m. 45/(1.6^2) = 45/2.56 â‰ˆ 17.6. Underweight.\n",
      "5. **Ethan**: 100 kg, 1.7 m. 100/(1.7^2) â‰ˆ 100/2.89 â‰ˆ 34.6. Obese.\n",
      "6. **Fiona**: 60 kg, 1.72 m. 60/(1.72^2) â‰ˆ 60/2.96 â‰ˆ 20.3. Normal.\n",
      "7. **George**: 120 kg, 1.85 m. 120/(1.85^2) â‰ˆ 120/3.42 â‰ˆ 35.1. Obese.\n",
      "8. **Hannah**: 55 kg, 1.68 m. 55/(1.68^2) â‰ˆ 55/2.82 â‰ˆ 19.5. Normal.\n",
      "9. **Ian**: 90 kg, 1.78 m. 90/(1.78^2) â‰ˆ 90/3.17 â‰ˆ 28.4. Overweight.\n",
      "10. **Julia**: 40 kg, 1.55 m. 40/(1.55^2) â‰ˆ 40/2.40 â‰ˆ 16.7. Underweight.\n",
      "\n",
      "The tool responses matched these calculations. Now, I need to format the results into JSON with each patient's name, BMI, and status. Let me make sure each entry is correct and the BMI is rounded appropriately. For example, Alice's BMI is 18.4, which is Underweight. Ethan's is 34.6, so Obese. All entries seem accurate. Time to structure the JSON response.\n",
      "</think>\n",
      "\n",
      "Here is the BMI and health status for each patient:\n",
      "\n",
      "```json\n",
      "[\n",
      "    {\"name\": \"Alice\", \"bmi\": 18.4, \"health_status\": \"Underweight\"},\n",
      "    {\"name\": \"Bob\", \"bmi\": 27.7, \"health_status\": \"Overweight\"},\n",
      "    {\"name\": \"Charlie\", \"bmi\": 21.6, \"health_status\": \"Normal\"},\n",
      "    {\"name\": \"Diana\", \"bmi\": 17.6, \"health_status\": \"Underweight\"},\n",
      "    {\"name\": \"Ethan\", \"bmi\": 34.6, \"health_status\": \"Obese\"},\n",
      "    {\"name\": \"Fiona\", \"bmi\": 20.3, \"health_status\": \"Normal\"},\n",
      "    {\"name\": \"George\", \"bmi\": 35.1, \"health_status\": \"Obese\"},\n",
      "    {\"name\": \"Hannah\", \"bmi\": 19.5, \"health_status\": \"Normal\"},\n",
      "    {\"name\": \"Ian\", \"bmi\": 28.4, \"health_status\": \"Overweight\"},\n",
      "    {\"name\": \"Julia\", \"bmi\": 16.7, \"health_status\": \"Underweight\"}\n",
      "]\n",
      "```"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AgentOutput(response=ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, additional_kwargs={'tool_calls': []}, blocks=[TextBlock(block_type='text', text='<think>\\nOkay, I need to process the patient data and calculate their BMI status. Let me start by recalling the BMI categories. BMI is calculated as weight divided by height squared. The categories are Underweight (BMI < 18.5), Normal (18.5â€“24.9), Overweight (25â€“29.9), and Obese (â‰¥30).\\n\\nLooking at the patients:\\n\\n1. **Alice**: Weight 50 kg, height 1.65 m. Let me calculate BMI: 50/(1.65^2) â‰ˆ 50/2.72 â‰ˆ 18.4. So Underweight.\\n2. **Bob**: 85 kg, 1.75 m. 85/(1.75^2) â‰ˆ 85/3.06 â‰ˆ 27.7. Overweight.\\n3. **Charlie**: 70 kg, 1.8 m. 70/(1.8^2) â‰ˆ 70/3.24 â‰ˆ 21.6. Normal.\\n4. **Diana**: 45 kg, 1.6 m. 45/(1.6^2) = 45/2.56 â‰ˆ 17.6. Underweight.\\n5. **Ethan**: 100 kg, 1.7 m. 100/(1.7^2) â‰ˆ 100/2.89 â‰ˆ 34.6. Obese.\\n6. **Fiona**: 60 kg, 1.72 m. 60/(1.72^2) â‰ˆ 60/2.96 â‰ˆ 20.3. Normal.\\n7. **George**: 120 kg, 1.85 m. 120/(1.85^2) â‰ˆ 120/3.42 â‰ˆ 35.1. Obese.\\n8. **Hannah**: 55 kg, 1.68 m. 55/(1.68^2) â‰ˆ 55/2.82 â‰ˆ 19.5. Normal.\\n9. **Ian**: 90 kg, 1.78 m. 90/(1.78^2) â‰ˆ 90/3.17 â‰ˆ 28.4. Overweight.\\n10. **Julia**: 40 kg, 1.55 m. 40/(1.55^2) â‰ˆ 40/2.40 â‰ˆ 16.7. Underweight.\\n\\nThe tool responses matched these calculations. Now, I need to format the results into JSON with each patient\\'s name, BMI, and status. Let me make sure each entry is correct and the BMI is rounded appropriately. For example, Alice\\'s BMI is 18.4, which is Underweight. Ethan\\'s is 34.6, so Obese. All entries seem accurate. Time to structure the JSON response.\\n</think>\\n\\nHere is the BMI and health status for each patient:\\n\\n```json\\n[\\n    {\"name\": \"Alice\", \"bmi\": 18.4, \"health_status\": \"Underweight\"},\\n    {\"name\": \"Bob\", \"bmi\": 27.7, \"health_status\": \"Overweight\"},\\n    {\"name\": \"Charlie\", \"bmi\": 21.6, \"health_status\": \"Normal\"},\\n    {\"name\": \"Diana\", \"bmi\": 17.6, \"health_status\": \"Underweight\"},\\n    {\"name\": \"Ethan\", \"bmi\": 34.6, \"health_status\": \"Obese\"},\\n    {\"name\": \"Fiona\", \"bmi\": 20.3, \"health_status\": \"Normal\"},\\n    {\"name\": \"George\", \"bmi\": 35.1, \"health_status\": \"Obese\"},\\n    {\"name\": \"Hannah\", \"bmi\": 19.5, \"health_status\": \"Normal\"},\\n    {\"name\": \"Ian\", \"bmi\": 28.4, \"health_status\": \"Overweight\"},\\n    {\"name\": \"Julia\", \"bmi\": 16.7, \"health_status\": \"Underweight\"}\\n]\\n```')]), tool_calls=[ToolCallResult(tool_name='bmi_status', tool_kwargs={'height': 1.65, 'weight': 50}, tool_id='bmi_status', tool_output=ToolOutput(content='Underweight', tool_name='bmi_status', raw_input={'args': (), 'kwargs': {'height': 1.65, 'weight': 50}}, raw_output='Underweight', is_error=False), return_direct=False), ToolCallResult(tool_name='bmi_status', tool_kwargs={'height': 1.75, 'weight': 85}, tool_id='bmi_status', tool_output=ToolOutput(content='Overweight', tool_name='bmi_status', raw_input={'args': (), 'kwargs': {'height': 1.75, 'weight': 85}}, raw_output='Overweight', is_error=False), return_direct=False), ToolCallResult(tool_name='bmi_status', tool_kwargs={'height': 1.8, 'weight': 70}, tool_id='bmi_status', tool_output=ToolOutput(content='Normal', tool_name='bmi_status', raw_input={'args': (), 'kwargs': {'height': 1.8, 'weight': 70}}, raw_output='Normal', is_error=False), return_direct=False), ToolCallResult(tool_name='bmi_status', tool_kwargs={'height': 1.6, 'weight': 45}, tool_id='bmi_status', tool_output=ToolOutput(content='Underweight', tool_name='bmi_status', raw_input={'args': (), 'kwargs': {'height': 1.6, 'weight': 45}}, raw_output='Underweight', is_error=False), return_direct=False), ToolCallResult(tool_name='bmi_status', tool_kwargs={'height': 1.7, 'weight': 100}, tool_id='bmi_status', tool_output=ToolOutput(content='Obese', tool_name='bmi_status', raw_input={'args': (), 'kwargs': {'height': 1.7, 'weight': 100}}, raw_output='Obese', is_error=False), return_direct=False), ToolCallResult(tool_name='bmi_status', tool_kwargs={'height': 1.72, 'weight': 60}, tool_id='bmi_status', tool_output=ToolOutput(content='Normal', tool_name='bmi_status', raw_input={'args': (), 'kwargs': {'height': 1.72, 'weight': 60}}, raw_output='Normal', is_error=False), return_direct=False), ToolCallResult(tool_name='bmi_status', tool_kwargs={'height': 1.85, 'weight': 120}, tool_id='bmi_status', tool_output=ToolOutput(content='Obese', tool_name='bmi_status', raw_input={'args': (), 'kwargs': {'height': 1.85, 'weight': 120}}, raw_output='Obese', is_error=False), return_direct=False), ToolCallResult(tool_name='bmi_status', tool_kwargs={'height': 1.68, 'weight': 55}, tool_id='bmi_status', tool_output=ToolOutput(content='Normal', tool_name='bmi_status', raw_input={'args': (), 'kwargs': {'height': 1.68, 'weight': 55}}, raw_output='Normal', is_error=False), return_direct=False), ToolCallResult(tool_name='bmi_status', tool_kwargs={'height': 1.78, 'weight': 90}, tool_id='bmi_status', tool_output=ToolOutput(content='Overweight', tool_name='bmi_status', raw_input={'args': (), 'kwargs': {'height': 1.78, 'weight': 90}}, raw_output='Overweight', is_error=False), return_direct=False), ToolCallResult(tool_name='bmi_status', tool_kwargs={'height': 1.55, 'weight': 40}, tool_id='bmi_status', tool_output=ToolOutput(content='Underweight', tool_name='bmi_status', raw_input={'args': (), 'kwargs': {'height': 1.55, 'weight': 40}}, raw_output='Underweight', is_error=False), return_direct=False)], raw={'model': 'qwen3:8b', 'created_at': '2025-05-18T13:32:35.508706Z', 'done': True, 'done_reason': 'stop', 'total_duration': 49396658000, 'load_duration': 26003542, 'prompt_eval_count': 756, 'prompt_eval_duration': 1253374541, 'eval_count': 944, 'eval_duration': 48085453959, 'message': Message(role='assistant', content='<think>\\nOkay, I need to process the patient data and calculate their BMI status. Let me start by recalling the BMI categories. BMI is calculated as weight divided by height squared. The categories are Underweight (BMI < 18.5), Normal (18.5â€“24.9), Overweight (25â€“29.9), and Obese (â‰¥30).\\n\\nLooking at the patients:\\n\\n1. **Alice**: Weight 50 kg, height 1.65 m. Let me calculate BMI: 50/(1.65^2) â‰ˆ 50/2.72 â‰ˆ 18.4. So Underweight.\\n2. **Bob**: 85 kg, 1.75 m. 85/(1.75^2) â‰ˆ 85/3.06 â‰ˆ 27.7. Overweight.\\n3. **Charlie**: 70 kg, 1.8 m. 70/(1.8^2) â‰ˆ 70/3.24 â‰ˆ 21.6. Normal.\\n4. **Diana**: 45 kg, 1.6 m. 45/(1.6^2) = 45/2.56 â‰ˆ 17.6. Underweight.\\n5. **Ethan**: 100 kg, 1.7 m. 100/(1.7^2) â‰ˆ 100/2.89 â‰ˆ 34.6. Obese.\\n6. **Fiona**: 60 kg, 1.72 m. 60/(1.72^2) â‰ˆ 60/2.96 â‰ˆ 20.3. Normal.\\n7. **George**: 120 kg, 1.85 m. 120/(1.85^2) â‰ˆ 120/3.42 â‰ˆ 35.1. Obese.\\n8. **Hannah**: 55 kg, 1.68 m. 55/(1.68^2) â‰ˆ 55/2.82 â‰ˆ 19.5. Normal.\\n9. **Ian**: 90 kg, 1.78 m. 90/(1.78^2) â‰ˆ 90/3.17 â‰ˆ 28.4. Overweight.\\n10. **Julia**: 40 kg, 1.55 m. 40/(1.55^2) â‰ˆ 40/2.40 â‰ˆ 16.7. Underweight.\\n\\nThe tool responses matched these calculations. Now, I need to format the results into JSON with each patient\\'s name, BMI, and status. Let me make sure each entry is correct and the BMI is rounded appropriately. For example, Alice\\'s BMI is 18.4, which is Underweight. Ethan\\'s is 34.6, so Obese. All entries seem accurate. Time to structure the JSON response.\\n</think>\\n\\nHere is the BMI and health status for each patient:\\n\\n```json\\n[\\n    {\"name\": \"Alice\", \"bmi\": 18.4, \"health_status\": \"Underweight\"},\\n    {\"name\": \"Bob\", \"bmi\": 27.7, \"health_status\": \"Overweight\"},\\n    {\"name\": \"Charlie\", \"bmi\": 21.6, \"health_status\": \"Normal\"},\\n    {\"name\": \"Diana\", \"bmi\": 17.6, \"health_status\": \"Underweight\"},\\n    {\"name\": \"Ethan\", \"bmi\": 34.6, \"health_status\": \"Obese\"},\\n    {\"name\": \"Fiona\", \"bmi\": 20.3, \"health_status\": \"Normal\"},\\n    {\"name\": \"George\", \"bmi\": 35.1, \"health_status\": \"Obese\"},\\n    {\"name\": \"Hannah\", \"bmi\": 19.5, \"health_status\": \"Normal\"},\\n    {\"name\": \"Ian\", \"bmi\": 28.4, \"health_status\": \"Overweight\"},\\n    {\"name\": \"Julia\", \"bmi\": 16.7, \"health_status\": \"Underweight\"}\\n]\\n```', images=None, tool_calls=None), 'usage': {'prompt_tokens': 756, 'completion_tokens': 944, 'total_tokens': 1700}}, current_agent_name='Agent')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run agent\n",
    "handler = agent.run(f\"\"\"\n",
    "    Patient Data: {data}\n",
    "    Calculate bmi and return status for these patients, return result in json format with name, bmi and health status.  \n",
    "\"\"\")\n",
    "async for ev in handler.stream_events():\n",
    "    if isinstance(ev, ToolCallResult):\n",
    "        print(\"\")\n",
    "        print(\"Called tool: \", ev.tool_name, ev.tool_kwargs, \"=>\", ev.tool_output)\n",
    "    elif isinstance(ev, AgentStream):  # showing the thought process\n",
    "        print(ev.delta, end=\"\", flush=True)\n",
    "\n",
    "resp = await handler\n",
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8f0afb3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Called tool:  bmi_status {'height': 1.65, 'weight': 50} => Underweight\n",
      "\n",
      "Called tool:  bmi_status {'height': 1.75, 'weight': 85} => Overweight\n",
      "\n",
      "Called tool:  bmi_status {'height': 1.8, 'weight': 70} => Normal\n",
      "\n",
      "Called tool:  bmi_status {'height': 1.6, 'weight': 45} => Underweight\n",
      "\n",
      "Called tool:  bmi_status {'height': 1.7, 'weight': 100} => Obese\n",
      "\n",
      "Called tool:  bmi_status {'height': 1.72, 'weight': 60} => Normal\n",
      "\n",
      "Called tool:  bmi_status {'height': 1.85, 'weight': 120} => Obese\n",
      "\n",
      "Called tool:  bmi_status {'height': 1.68, 'weight': 55} => Normal\n",
      "\n",
      "Called tool:  bmi_status {'height': 1.78, 'weight': 90} => Overweight\n",
      "\n",
      "Called tool:  bmi_status {'height': 1.55, 'weight': 40} => Underweight\n",
      "<think>\n",
      "Okay, let me start by understanding the user's request. They provided a list of patient data with names, weights, and heights. The task is to calculate the BMI for each patient and determine their health status using the bmi_status function. Then, compile the results into a pandas DataFrame with columns for name, BMI, and health status.\n",
      "\n",
      "First, I need to recall how BMI is calculated. BMI is weight (kg) divided by height (m) squared. The function provided, bmi_status, takes weight and height as parameters and returns the category. The categories are Underweight, Normal, Overweight, or Obese. \n",
      "\n",
      "Looking at the patient data, each entry has a name, weight, and height. For each patient, I'll need to call the bmi_status function with their specific weight and height. The user already provided the function calls and the responses, so I can use those results to populate the DataFrame.\n",
      "\n",
      "Wait, the user included the function calls and the tool responses. The tool responses gave the status for each patient. Now, I need to calculate the actual BMI values to include in the DataFrame. The function might not return the BMI value itself, only the category. But the user wants the BMI value in the DataFrame. Hmm, that's a problem. The function provided only returns the status, not the BMI calculation. \n",
      "\n",
      "Wait, the function's description says it calculates BMI and returns the category. But the parameters are weight and height. Maybe the function actually computes BMI and returns the category, but the user wants the BMI value in the DataFrame. However, the function's return is only the status. So perhaps the user expects me to compute BMI manually using the weight and height, then use the function to get the status. \n",
      "\n",
      "Wait, the user's initial instruction says to use the provided tools. The tool is the bmi_status function, which returns the category. But the user wants the BMI value in the DataFrame. Since the function doesn't return BMI, maybe I need to calculate BMI manually. But the user might have intended that the function also returns BMI. However, according to the function definition, it only returns the category. \n",
      "\n",
      "This is a conflict. The user asked for BMI and status. The function only gives status. So perhaps the user made a mistake in the function definition. Alternatively, maybe the function actually returns BMI as part of the response. But according to the tool definition, the function's return is the category. \n",
      "\n",
      "Wait, looking back at the function definition: the description says it calculates BMI and returns the category. The parameters are weight and height. So the function's output is the category. Therefore, to get the BMI value, I need to calculate it using weight divided by height squared. Then, use the function to get the status. \n",
      "\n",
      "So, for each patient, I need to compute BMI manually and then get the status via the function. However, the user already called the function for each patient and got the status. The tool responses provided the status for each. Now, I need to compute the BMI value for each patient and combine it with the status. \n",
      "\n",
      "But the user's initial request was to return a pandas DataFrame with name, BMI, and health status. Since the function only gives the status, I need to calculate BMI separately. However, the user might have intended that the function returns both BMI and status, but according to the tool definition, it only returns the status. \n",
      "\n",
      "This is a bit confusing. But since the user provided the function calls and the tool responses, perhaps they expect me to use the function's status and compute the BMI manually. \n",
      "\n",
      "So, let me proceed step by step. For each patient:\n",
      "\n",
      "1. Calculate BMI using weight / (height^2).\n",
      "2. Use the function to get the status (already provided in the tool responses).\n",
      "3. Compile into a DataFrame with name, BMI, and status.\n",
      "\n",
      "Let me check each patient:\n",
      "\n",
      "- Alice: weight 50 kg, height 1.65 m. BMI = 50/(1.65^2) â‰ˆ 50/2.7225 â‰ˆ 18.37. Status: Underweight.\n",
      "- Bob: 85/(1.75^2) = 85/3.0625 â‰ˆ 27.76. Status: Overweight.\n",
      "- Charlie: 70/(1.8^2) = 70/3.24 â‰ˆ 21.6. Status: Normal.\n",
      "- Diana: 45/(1.6^2) = 45/2.56 â‰ˆ 17.58. Status: Underweight.\n",
      "- Ethan: 100/(1.7^2) = 100/2.89 â‰ˆ 34.6. Status: Obese.\n",
      "- Fiona: 60/(1.72^2) â‰ˆ 60/2.9584 â‰ˆ 20.28. Status: Normal.\n",
      "- George: 120/(1.85^2) â‰ˆ 120/3.4225 â‰ˆ 35.07. Status: Obese.\n",
      "- Hannah: 55/(1.68^2) â‰ˆ 55/2.8224 â‰ˆ 19.49. Status: Normal.\n",
      "- Ian: 90/(1.78^2) â‰ˆ 90/3.1684 â‰ˆ 28.41. Status: Overweight.\n",
      "- Julia: 40/(1.55^2) â‰ˆ 40/2.4025 â‰ˆ 16.65. Status: Underweight.\n",
      "\n",
      "Now, compiling all these into a DataFrame with columns Name, BMI, Health Status. The user wants this in pandas, but since the assistant can't execute code, the answer should present the data in a tabular format as requested. However, the user might expect the actual BMI values. So the final answer should list each patient with their BMI and status.\n",
      "</think>\n",
      "\n",
      "Here is the BMI and health status for each patient:\n",
      "\n",
      "| Name    | BMI     | Health Status |\n",
      "|---------|---------|---------------|\n",
      "| Alice   | 18.37   | Underweight   |\n",
      "| Bob     | 27.76   | Overweight    |\n",
      "| Charlie | 21.60   | Normal        |\n",
      "| Diana   | 17.58   | Underweight   |\n",
      "| Ethan   | 34.60   | Obese         |\n",
      "| Fiona   | 20.28   | Normal        |\n",
      "| George  | 35.07   | Obese         |\n",
      "| Hannah  | 19.49   | Normal        |\n",
      "| Ian     | 28.41   | Overweight    |\n",
      "| Julia   | 16.65   | Underweight   |\n",
      "\n",
      "The BMI is calculated as `weight (kg) / heightÂ² (mÂ²)`, and the health status is determined using standard BMI categories."
     ]
    },
    {
     "data": {
      "text/plain": [
       "AgentOutput(response=ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, additional_kwargs={'tool_calls': []}, blocks=[TextBlock(block_type='text', text=\"<think>\\nOkay, let me start by understanding the user's request. They provided a list of patient data with names, weights, and heights. The task is to calculate the BMI for each patient and determine their health status using the bmi_status function. Then, compile the results into a pandas DataFrame with columns for name, BMI, and health status.\\n\\nFirst, I need to recall how BMI is calculated. BMI is weight (kg) divided by height (m) squared. The function provided, bmi_status, takes weight and height as parameters and returns the category. The categories are Underweight, Normal, Overweight, or Obese. \\n\\nLooking at the patient data, each entry has a name, weight, and height. For each patient, I'll need to call the bmi_status function with their specific weight and height. The user already provided the function calls and the responses, so I can use those results to populate the DataFrame.\\n\\nWait, the user included the function calls and the tool responses. The tool responses gave the status for each patient. Now, I need to calculate the actual BMI values to include in the DataFrame. The function might not return the BMI value itself, only the category. But the user wants the BMI value in the DataFrame. Hmm, that's a problem. The function provided only returns the status, not the BMI calculation. \\n\\nWait, the function's description says it calculates BMI and returns the category. But the parameters are weight and height. Maybe the function actually computes BMI and returns the category, but the user wants the BMI value in the DataFrame. However, the function's return is only the status. So perhaps the user expects me to compute BMI manually using the weight and height, then use the function to get the status. \\n\\nWait, the user's initial instruction says to use the provided tools. The tool is the bmi_status function, which returns the category. But the user wants the BMI value in the DataFrame. Since the function doesn't return BMI, maybe I need to calculate BMI manually. But the user might have intended that the function also returns BMI. However, according to the function definition, it only returns the category. \\n\\nThis is a conflict. The user asked for BMI and status. The function only gives status. So perhaps the user made a mistake in the function definition. Alternatively, maybe the function actually returns BMI as part of the response. But according to the tool definition, the function's return is the category. \\n\\nWait, looking back at the function definition: the description says it calculates BMI and returns the category. The parameters are weight and height. So the function's output is the category. Therefore, to get the BMI value, I need to calculate it using weight divided by height squared. Then, use the function to get the status. \\n\\nSo, for each patient, I need to compute BMI manually and then get the status via the function. However, the user already called the function for each patient and got the status. The tool responses provided the status for each. Now, I need to compute the BMI value for each patient and combine it with the status. \\n\\nBut the user's initial request was to return a pandas DataFrame with name, BMI, and health status. Since the function only gives the status, I need to calculate BMI separately. However, the user might have intended that the function returns both BMI and status, but according to the tool definition, it only returns the status. \\n\\nThis is a bit confusing. But since the user provided the function calls and the tool responses, perhaps they expect me to use the function's status and compute the BMI manually. \\n\\nSo, let me proceed step by step. For each patient:\\n\\n1. Calculate BMI using weight / (height^2).\\n2. Use the function to get the status (already provided in the tool responses).\\n3. Compile into a DataFrame with name, BMI, and status.\\n\\nLet me check each patient:\\n\\n- Alice: weight 50 kg, height 1.65 m. BMI = 50/(1.65^2) â‰ˆ 50/2.7225 â‰ˆ 18.37. Status: Underweight.\\n- Bob: 85/(1.75^2) = 85/3.0625 â‰ˆ 27.76. Status: Overweight.\\n- Charlie: 70/(1.8^2) = 70/3.24 â‰ˆ 21.6. Status: Normal.\\n- Diana: 45/(1.6^2) = 45/2.56 â‰ˆ 17.58. Status: Underweight.\\n- Ethan: 100/(1.7^2) = 100/2.89 â‰ˆ 34.6. Status: Obese.\\n- Fiona: 60/(1.72^2) â‰ˆ 60/2.9584 â‰ˆ 20.28. Status: Normal.\\n- George: 120/(1.85^2) â‰ˆ 120/3.4225 â‰ˆ 35.07. Status: Obese.\\n- Hannah: 55/(1.68^2) â‰ˆ 55/2.8224 â‰ˆ 19.49. Status: Normal.\\n- Ian: 90/(1.78^2) â‰ˆ 90/3.1684 â‰ˆ 28.41. Status: Overweight.\\n- Julia: 40/(1.55^2) â‰ˆ 40/2.4025 â‰ˆ 16.65. Status: Underweight.\\n\\nNow, compiling all these into a DataFrame with columns Name, BMI, Health Status. The user wants this in pandas, but since the assistant can't execute code, the answer should present the data in a tabular format as requested. However, the user might expect the actual BMI values. So the final answer should list each patient with their BMI and status.\\n</think>\\n\\nHere is the BMI and health status for each patient:\\n\\n| Name    | BMI     | Health Status |\\n|---------|---------|---------------|\\n| Alice   | 18.37   | Underweight   |\\n| Bob     | 27.76   | Overweight    |\\n| Charlie | 21.60   | Normal        |\\n| Diana   | 17.58   | Underweight   |\\n| Ethan   | 34.60   | Obese         |\\n| Fiona   | 20.28   | Normal        |\\n| George  | 35.07   | Obese         |\\n| Hannah  | 19.49   | Normal        |\\n| Ian     | 28.41   | Overweight    |\\n| Julia   | 16.65   | Underweight   |\\n\\nThe BMI is calculated as `weight (kg) / heightÂ² (mÂ²)`, and the health status is determined using standard BMI categories.\")]), tool_calls=[ToolCallResult(tool_name='bmi_status', tool_kwargs={'height': 1.65, 'weight': 50}, tool_id='bmi_status', tool_output=ToolOutput(content='Underweight', tool_name='bmi_status', raw_input={'args': (), 'kwargs': {'height': 1.65, 'weight': 50}}, raw_output='Underweight', is_error=False), return_direct=False), ToolCallResult(tool_name='bmi_status', tool_kwargs={'height': 1.75, 'weight': 85}, tool_id='bmi_status', tool_output=ToolOutput(content='Overweight', tool_name='bmi_status', raw_input={'args': (), 'kwargs': {'height': 1.75, 'weight': 85}}, raw_output='Overweight', is_error=False), return_direct=False), ToolCallResult(tool_name='bmi_status', tool_kwargs={'height': 1.8, 'weight': 70}, tool_id='bmi_status', tool_output=ToolOutput(content='Normal', tool_name='bmi_status', raw_input={'args': (), 'kwargs': {'height': 1.8, 'weight': 70}}, raw_output='Normal', is_error=False), return_direct=False), ToolCallResult(tool_name='bmi_status', tool_kwargs={'height': 1.6, 'weight': 45}, tool_id='bmi_status', tool_output=ToolOutput(content='Underweight', tool_name='bmi_status', raw_input={'args': (), 'kwargs': {'height': 1.6, 'weight': 45}}, raw_output='Underweight', is_error=False), return_direct=False), ToolCallResult(tool_name='bmi_status', tool_kwargs={'height': 1.7, 'weight': 100}, tool_id='bmi_status', tool_output=ToolOutput(content='Obese', tool_name='bmi_status', raw_input={'args': (), 'kwargs': {'height': 1.7, 'weight': 100}}, raw_output='Obese', is_error=False), return_direct=False), ToolCallResult(tool_name='bmi_status', tool_kwargs={'height': 1.72, 'weight': 60}, tool_id='bmi_status', tool_output=ToolOutput(content='Normal', tool_name='bmi_status', raw_input={'args': (), 'kwargs': {'height': 1.72, 'weight': 60}}, raw_output='Normal', is_error=False), return_direct=False), ToolCallResult(tool_name='bmi_status', tool_kwargs={'height': 1.85, 'weight': 120}, tool_id='bmi_status', tool_output=ToolOutput(content='Obese', tool_name='bmi_status', raw_input={'args': (), 'kwargs': {'height': 1.85, 'weight': 120}}, raw_output='Obese', is_error=False), return_direct=False), ToolCallResult(tool_name='bmi_status', tool_kwargs={'height': 1.68, 'weight': 55}, tool_id='bmi_status', tool_output=ToolOutput(content='Normal', tool_name='bmi_status', raw_input={'args': (), 'kwargs': {'height': 1.68, 'weight': 55}}, raw_output='Normal', is_error=False), return_direct=False), ToolCallResult(tool_name='bmi_status', tool_kwargs={'height': 1.78, 'weight': 90}, tool_id='bmi_status', tool_output=ToolOutput(content='Overweight', tool_name='bmi_status', raw_input={'args': (), 'kwargs': {'height': 1.78, 'weight': 90}}, raw_output='Overweight', is_error=False), return_direct=False), ToolCallResult(tool_name='bmi_status', tool_kwargs={'height': 1.55, 'weight': 40}, tool_id='bmi_status', tool_output=ToolOutput(content='Underweight', tool_name='bmi_status', raw_input={'args': (), 'kwargs': {'height': 1.55, 'weight': 40}}, raw_output='Underweight', is_error=False), return_direct=False)], raw={'model': 'qwen3:8b', 'created_at': '2025-05-18T13:38:09.785652Z', 'done': True, 'done_reason': 'stop', 'total_duration': 74040543750, 'load_duration': 31661791, 'prompt_eval_count': 756, 'prompt_eval_duration': 1243645166, 'eval_count': 1485, 'eval_duration': 72709653792, 'message': Message(role='assistant', content=\"<think>\\nOkay, let me start by understanding the user's request. They provided a list of patient data with names, weights, and heights. The task is to calculate the BMI for each patient and determine their health status using the bmi_status function. Then, compile the results into a pandas DataFrame with columns for name, BMI, and health status.\\n\\nFirst, I need to recall how BMI is calculated. BMI is weight (kg) divided by height (m) squared. The function provided, bmi_status, takes weight and height as parameters and returns the category. The categories are Underweight, Normal, Overweight, or Obese. \\n\\nLooking at the patient data, each entry has a name, weight, and height. For each patient, I'll need to call the bmi_status function with their specific weight and height. The user already provided the function calls and the responses, so I can use those results to populate the DataFrame.\\n\\nWait, the user included the function calls and the tool responses. The tool responses gave the status for each patient. Now, I need to calculate the actual BMI values to include in the DataFrame. The function might not return the BMI value itself, only the category. But the user wants the BMI value in the DataFrame. Hmm, that's a problem. The function provided only returns the status, not the BMI calculation. \\n\\nWait, the function's description says it calculates BMI and returns the category. But the parameters are weight and height. Maybe the function actually computes BMI and returns the category, but the user wants the BMI value in the DataFrame. However, the function's return is only the status. So perhaps the user expects me to compute BMI manually using the weight and height, then use the function to get the status. \\n\\nWait, the user's initial instruction says to use the provided tools. The tool is the bmi_status function, which returns the category. But the user wants the BMI value in the DataFrame. Since the function doesn't return BMI, maybe I need to calculate BMI manually. But the user might have intended that the function also returns BMI. However, according to the function definition, it only returns the category. \\n\\nThis is a conflict. The user asked for BMI and status. The function only gives status. So perhaps the user made a mistake in the function definition. Alternatively, maybe the function actually returns BMI as part of the response. But according to the tool definition, the function's return is the category. \\n\\nWait, looking back at the function definition: the description says it calculates BMI and returns the category. The parameters are weight and height. So the function's output is the category. Therefore, to get the BMI value, I need to calculate it using weight divided by height squared. Then, use the function to get the status. \\n\\nSo, for each patient, I need to compute BMI manually and then get the status via the function. However, the user already called the function for each patient and got the status. The tool responses provided the status for each. Now, I need to compute the BMI value for each patient and combine it with the status. \\n\\nBut the user's initial request was to return a pandas DataFrame with name, BMI, and health status. Since the function only gives the status, I need to calculate BMI separately. However, the user might have intended that the function returns both BMI and status, but according to the tool definition, it only returns the status. \\n\\nThis is a bit confusing. But since the user provided the function calls and the tool responses, perhaps they expect me to use the function's status and compute the BMI manually. \\n\\nSo, let me proceed step by step. For each patient:\\n\\n1. Calculate BMI using weight / (height^2).\\n2. Use the function to get the status (already provided in the tool responses).\\n3. Compile into a DataFrame with name, BMI, and status.\\n\\nLet me check each patient:\\n\\n- Alice: weight 50 kg, height 1.65 m. BMI = 50/(1.65^2) â‰ˆ 50/2.7225 â‰ˆ 18.37. Status: Underweight.\\n- Bob: 85/(1.75^2) = 85/3.0625 â‰ˆ 27.76. Status: Overweight.\\n- Charlie: 70/(1.8^2) = 70/3.24 â‰ˆ 21.6. Status: Normal.\\n- Diana: 45/(1.6^2) = 45/2.56 â‰ˆ 17.58. Status: Underweight.\\n- Ethan: 100/(1.7^2) = 100/2.89 â‰ˆ 34.6. Status: Obese.\\n- Fiona: 60/(1.72^2) â‰ˆ 60/2.9584 â‰ˆ 20.28. Status: Normal.\\n- George: 120/(1.85^2) â‰ˆ 120/3.4225 â‰ˆ 35.07. Status: Obese.\\n- Hannah: 55/(1.68^2) â‰ˆ 55/2.8224 â‰ˆ 19.49. Status: Normal.\\n- Ian: 90/(1.78^2) â‰ˆ 90/3.1684 â‰ˆ 28.41. Status: Overweight.\\n- Julia: 40/(1.55^2) â‰ˆ 40/2.4025 â‰ˆ 16.65. Status: Underweight.\\n\\nNow, compiling all these into a DataFrame with columns Name, BMI, Health Status. The user wants this in pandas, but since the assistant can't execute code, the answer should present the data in a tabular format as requested. However, the user might expect the actual BMI values. So the final answer should list each patient with their BMI and status.\\n</think>\\n\\nHere is the BMI and health status for each patient:\\n\\n| Name    | BMI     | Health Status |\\n|---------|---------|---------------|\\n| Alice   | 18.37   | Underweight   |\\n| Bob     | 27.76   | Overweight    |\\n| Charlie | 21.60   | Normal        |\\n| Diana   | 17.58   | Underweight   |\\n| Ethan   | 34.60   | Obese         |\\n| Fiona   | 20.28   | Normal        |\\n| George  | 35.07   | Obese         |\\n| Hannah  | 19.49   | Normal        |\\n| Ian     | 28.41   | Overweight    |\\n| Julia   | 16.65   | Underweight   |\\n\\nThe BMI is calculated as `weight (kg) / heightÂ² (mÂ²)`, and the health status is determined using standard BMI categories.\", images=None, tool_calls=None), 'usage': {'prompt_tokens': 756, 'completion_tokens': 1485, 'total_tokens': 2241}}, current_agent_name='Agent')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run agent\n",
    "handler = agent.run(f\"\"\"\n",
    "    Patient Data: {data}\n",
    "    Calculate bmi and return status for these patients, return as a pandas dataframe with name, bmi and health status. \n",
    "\"\"\")\n",
    "async for ev in handler.stream_events():\n",
    "    if isinstance(ev, ToolCallResult):\n",
    "        print(\"\")\n",
    "        print(\"Called tool: \", ev.tool_name, ev.tool_kwargs, \"=>\", ev.tool_output)\n",
    "    elif isinstance(ev, AgentStream):  # showing the thought process\n",
    "        print(ev.delta, end=\"\", flush=True)\n",
    "\n",
    "resp = await handler\n",
    "resp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5838b263",
   "metadata": {},
   "source": [
    "## Create RAG Agents with `QueryEngineTool`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d441944a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core.tools import QueryEngineTool\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "\n",
    "# Create vector store\n",
    "db = chromadb.PersistentClient(path=\"./alfred_chroma_db\")\n",
    "chroma_collection = db.get_or_create_collection(\"alfred\")\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "\n",
    "# Create query engine\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n",
    "llm = Ollama(model=\"qwen3:8b\", request_timeout=60.0)\n",
    "index = VectorStoreIndex.from_vector_store(\n",
    "    vector_store=vector_store, embed_model=embed_model\n",
    ")\n",
    "query_engine = index.as_query_engine(llm=llm)\n",
    "query_engine_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=query_engine,\n",
    "    name=\"personas\",\n",
    "    description=\"descriptions for various types of personas\",\n",
    "    return_direct=False,\n",
    ")\n",
    "\n",
    "# Create RAG agent\n",
    "query_engine_agent = AgentWorkflow.from_tools_or_functions(\n",
    "    tools_or_functions=[query_engine_tool], \n",
    "    llm=llm, \n",
    "    system_prompt=\"You are a helpful assistant that has access to a database containing persona descriptions. \",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7b9e1180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Called tool:  personas {'input': 'dance educator'} => <think>\n",
      "Okay, the user is asking about a \"dance educator\" in the context of the provided information. Let me check the context again. The context mentions a social justice educator or activist focused on diversity, equity, and inclusion, working with families and communities to promote empathy and understanding of intersectional identity and oppression. The file path is repeated twice, but the content is the same.\n",
      "\n",
      "Now, the query is \"dance educator.\" The answer needs to be based solely on the context given. The context doesn't mention dance specifically. It talks about a social justice educator, which could be in any field, like education, activism, etc. But there's no direct link to dance. However, maybe the user is implying that the dance educator is part of the social justice work mentioned. But the context doesn't specify that. Since the answer must not reference the context directly, I need to infer based on the given info. The answer should be that the persona is a social justice educator focused on DEI, working with communities, but not specifically a dance educator. Wait, but the query is about a dance educator. The context doesn't mention dance, so perhaps the answer is that there's no direct information about a dance educator in the context. But the user might be expecting a connection. Wait, maybe the answer is that the persona could be a dance educator if they work in that field, but the context doesn't specify. But the instructions say to not use prior knowledge. So strictly based on the context, the answer should be that the persona is a social justice educator focused on DEI, working with families and communities. The query is about a dance educator, but the context doesn't mention dance. Therefore, the answer should state that the persona is a social justice educator, but not specifically a dance educator unless inferred. Wait, the user's query is \"dance educator,\" so maybe they want to know if the persona is that. But the context doesn't mention dance. So the answer should be that the context doesn't provide information about a dance educator. But the user might have provided the context where the persona is a social justice educator, which could be in any field. So the answer should state that the persona is a social justice educator focused on DEI, but not specifically a dance educator. However, the user's query is \"dance educator,\" so the answer should be that the context doesn't mention a dance educator, but the persona is a social justice educator. Wait, but the answer needs to be based on the context. The context says the persona is a social justice educator or activist focused on DEI, working with families and communities. So the answer should be that the persona is a social justice educator, not specifically a dance educator. But the query is \"dance educator,\" so perhaps the answer is that the context doesn't mention a dance educator. However, the user might be expecting that the answer is that the persona is a dance educator, but that's not stated. So the correct answer is that the context describes a social justice educator, not specifically a dance educator. Therefore, the answer is that the persona is a social justice educator focused on DEI, working with communities, but the query about a dance educator isn't addressed in the context.\n",
      "</think>\n",
      "\n",
      "The persona described is a social justice educator or activist focused on promoting diversity, equity, and inclusion through work with families and communities. While the role involves fostering empathy and understanding of intersectional identity and oppression, there is no specific mention of dance education or related activities in the provided context.\n",
      "<think>\n",
      "</think>\n",
      "\n",
      "The persona described is a social justice educator or activist focused on promoting diversity, equity, and inclusion through work with families and communities. While the role involves fostering empathy and understanding of intersectional identity and oppression, there is no specific mention of dance education or related activities in the provided context."
     ]
    },
    {
     "data": {
      "text/plain": [
       "AgentOutput(response=ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, additional_kwargs={'tool_calls': []}, blocks=[TextBlock(block_type='text', text='<think>\\n</think>\\n\\nThe persona described is a social justice educator or activist focused on promoting diversity, equity, and inclusion through work with families and communities. While the role involves fostering empathy and understanding of intersectional identity and oppression, there is no specific mention of dance education or related activities in the provided context.')]), tool_calls=[ToolCallResult(tool_name='personas', tool_kwargs={'input': 'dance educator'}, tool_id='personas', tool_output=ToolOutput(content='<think>\\nOkay, the user is asking about a \"dance educator\" in the context of the provided information. Let me check the context again. The context mentions a social justice educator or activist focused on diversity, equity, and inclusion, working with families and communities to promote empathy and understanding of intersectional identity and oppression. The file path is repeated twice, but the content is the same.\\n\\nNow, the query is \"dance educator.\" The answer needs to be based solely on the context given. The context doesn\\'t mention dance specifically. It talks about a social justice educator, which could be in any field, like education, activism, etc. But there\\'s no direct link to dance. However, maybe the user is implying that the dance educator is part of the social justice work mentioned. But the context doesn\\'t specify that. Since the answer must not reference the context directly, I need to infer based on the given info. The answer should be that the persona is a social justice educator focused on DEI, working with communities, but not specifically a dance educator. Wait, but the query is about a dance educator. The context doesn\\'t mention dance, so perhaps the answer is that there\\'s no direct information about a dance educator in the context. But the user might be expecting a connection. Wait, maybe the answer is that the persona could be a dance educator if they work in that field, but the context doesn\\'t specify. But the instructions say to not use prior knowledge. So strictly based on the context, the answer should be that the persona is a social justice educator focused on DEI, working with families and communities. The query is about a dance educator, but the context doesn\\'t mention dance. Therefore, the answer should state that the persona is a social justice educator, but not specifically a dance educator unless inferred. Wait, the user\\'s query is \"dance educator,\" so maybe they want to know if the persona is that. But the context doesn\\'t mention dance. So the answer should be that the context doesn\\'t provide information about a dance educator. But the user might have provided the context where the persona is a social justice educator, which could be in any field. So the answer should state that the persona is a social justice educator focused on DEI, but not specifically a dance educator. However, the user\\'s query is \"dance educator,\" so the answer should be that the context doesn\\'t mention a dance educator, but the persona is a social justice educator. Wait, but the answer needs to be based on the context. The context says the persona is a social justice educator or activist focused on DEI, working with families and communities. So the answer should be that the persona is a social justice educator, not specifically a dance educator. But the query is \"dance educator,\" so perhaps the answer is that the context doesn\\'t mention a dance educator. However, the user might be expecting that the answer is that the persona is a dance educator, but that\\'s not stated. So the correct answer is that the context describes a social justice educator, not specifically a dance educator. Therefore, the answer is that the persona is a social justice educator focused on DEI, working with communities, but the query about a dance educator isn\\'t addressed in the context.\\n</think>\\n\\nThe persona described is a social justice educator or activist focused on promoting diversity, equity, and inclusion through work with families and communities. While the role involves fostering empathy and understanding of intersectional identity and oppression, there is no specific mention of dance education or related activities in the provided context.', tool_name='personas', raw_input={'input': 'dance educator'}, raw_output=Response(response='<think>\\nOkay, the user is asking about a \"dance educator\" in the context of the provided information. Let me check the context again. The context mentions a social justice educator or activist focused on diversity, equity, and inclusion, working with families and communities to promote empathy and understanding of intersectional identity and oppression. The file path is repeated twice, but the content is the same.\\n\\nNow, the query is \"dance educator.\" The answer needs to be based solely on the context given. The context doesn\\'t mention dance specifically. It talks about a social justice educator, which could be in any field, like education, activism, etc. But there\\'s no direct link to dance. However, maybe the user is implying that the dance educator is part of the social justice work mentioned. But the context doesn\\'t specify that. Since the answer must not reference the context directly, I need to infer based on the given info. The answer should be that the persona is a social justice educator focused on DEI, working with communities, but not specifically a dance educator. Wait, but the query is about a dance educator. The context doesn\\'t mention dance, so perhaps the answer is that there\\'s no direct information about a dance educator in the context. But the user might be expecting a connection. Wait, maybe the answer is that the persona could be a dance educator if they work in that field, but the context doesn\\'t specify. But the instructions say to not use prior knowledge. So strictly based on the context, the answer should be that the persona is a social justice educator focused on DEI, working with families and communities. The query is about a dance educator, but the context doesn\\'t mention dance. Therefore, the answer should state that the persona is a social justice educator, but not specifically a dance educator unless inferred. Wait, the user\\'s query is \"dance educator,\" so maybe they want to know if the persona is that. But the context doesn\\'t mention dance. So the answer should be that the context doesn\\'t provide information about a dance educator. But the user might have provided the context where the persona is a social justice educator, which could be in any field. So the answer should state that the persona is a social justice educator focused on DEI, but not specifically a dance educator. However, the user\\'s query is \"dance educator,\" so the answer should be that the context doesn\\'t mention a dance educator, but the persona is a social justice educator. Wait, but the answer needs to be based on the context. The context says the persona is a social justice educator or activist focused on DEI, working with families and communities. So the answer should be that the persona is a social justice educator, not specifically a dance educator. But the query is \"dance educator,\" so perhaps the answer is that the context doesn\\'t mention a dance educator. However, the user might be expecting that the answer is that the persona is a dance educator, but that\\'s not stated. So the correct answer is that the context describes a social justice educator, not specifically a dance educator. Therefore, the answer is that the persona is a social justice educator focused on DEI, working with communities, but the query about a dance educator isn\\'t addressed in the context.\\n</think>\\n\\nThe persona described is a social justice educator or activist focused on promoting diversity, equity, and inclusion through work with families and communities. While the role involves fostering empathy and understanding of intersectional identity and oppression, there is no specific mention of dance education or related activities in the provided context.', source_nodes=[NodeWithScore(node=TextNode(id_='c6013a18-c856-4209-934a-0e66feb5568d', embedding=None, metadata={'file_path': '/Users/karen/Documents/02_AIE Journey/02_Study/05_Agents/01_HF Agents Course/data/persona_10.txt', 'file_name': 'persona_10.txt', 'file_type': 'text/plain', 'file_size': 207, 'creation_date': '2025-05-16', 'last_modified_date': '2025-05-16'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='6eb674fc-ae92-494c-b2e3-c702f53cade7', node_type='4', metadata={'file_path': '/Users/karen/Documents/02_AIE Journey/02_Study/05_Agents/01_HF Agents Course/data/persona_10.txt', 'file_name': 'persona_10.txt', 'file_type': 'text/plain', 'file_size': 207, 'creation_date': '2025-05-16', 'last_modified_date': '2025-05-16'}, hash='e5cfcdfbeba0e72b369b9c8f499d77ccd237dadba54beb3df160599ade1adf72')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='A social justice educator or activist focused on diversity, equity, and inclusion, likely working with families and communities to promote empathy and understanding of intersectional identity and oppression.', mimetype='text/plain', start_char_idx=0, end_char_idx=207, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.5292671948546535), NodeWithScore(node=TextNode(id_='233731c9-9cdb-4e6e-a548-1659e7327557', embedding=None, metadata={'file_path': '/Users/karen/Documents/02_AIE Journey/02_Study/05_Agents/01_HF Agents Course/data/persona_10.txt', 'file_name': 'persona_10.txt', 'file_type': 'text/plain', 'file_size': 207, 'creation_date': '2025-05-16', 'last_modified_date': '2025-05-16'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='2e578036-21c9-467e-ad5d-6954c496858c', node_type='4', metadata={'file_path': '/Users/karen/Documents/02_AIE Journey/02_Study/05_Agents/01_HF Agents Course/data/persona_10.txt', 'file_name': 'persona_10.txt', 'file_type': 'text/plain', 'file_size': 207, 'creation_date': '2025-05-16', 'last_modified_date': '2025-05-16'}, hash='e5cfcdfbeba0e72b369b9c8f499d77ccd237dadba54beb3df160599ade1adf72')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='A social justice educator or activist focused on diversity, equity, and inclusion, likely working with families and communities to promote empathy and understanding of intersectional identity and oppression.', mimetype='text/plain', start_char_idx=0, end_char_idx=207, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.5292671948546535)], metadata={'c6013a18-c856-4209-934a-0e66feb5568d': {'file_path': '/Users/karen/Documents/02_AIE Journey/02_Study/05_Agents/01_HF Agents Course/data/persona_10.txt', 'file_name': 'persona_10.txt', 'file_type': 'text/plain', 'file_size': 207, 'creation_date': '2025-05-16', 'last_modified_date': '2025-05-16'}, '233731c9-9cdb-4e6e-a548-1659e7327557': {'file_path': '/Users/karen/Documents/02_AIE Journey/02_Study/05_Agents/01_HF Agents Course/data/persona_10.txt', 'file_name': 'persona_10.txt', 'file_type': 'text/plain', 'file_size': 207, 'creation_date': '2025-05-16', 'last_modified_date': '2025-05-16'}}), is_error=False), return_direct=False)], raw={'model': 'qwen3:8b', 'created_at': '2025-05-18T13:44:31.596192Z', 'done': True, 'done_reason': 'stop', 'total_duration': 6794098875, 'load_duration': 24986875, 'prompt_eval_count': 917, 'prompt_eval_duration': 3955735833, 'eval_count': 62, 'eval_duration': 2792060084, 'message': Message(role='assistant', content='<think>\\n</think>\\n\\nThe persona described is a social justice educator or activist focused on promoting diversity, equity, and inclusion through work with families and communities. While the role involves fostering empathy and understanding of intersectional identity and oppression, there is no specific mention of dance education or related activities in the provided context.', images=None, tool_calls=None), 'usage': {'prompt_tokens': 917, 'completion_tokens': 62, 'total_tokens': 979}}, current_agent_name='Agent')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run agent\n",
    "handler = query_engine_agent.run(\"Search the database for dance educator and return some persona descriptions.\")\n",
    "async for ev in handler.stream_events():\n",
    "    if isinstance(ev, ToolCallResult):\n",
    "        print(\"\")\n",
    "        print(\"Called tool: \", ev.tool_name, ev.tool_kwargs, \"=>\", ev.tool_output)\n",
    "    elif isinstance(ev, AgentStream):  # showing thought process\n",
    "        print(ev.delta, end=\"\", flush=True)\n",
    "\n",
    "resp = await handler\n",
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ef9df7d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Called tool:  personas {'input': 'law professor'} => <think>\n",
      "Okay, the user asked about a \"law professor\" and provided some context files. Let me check the context info. The files mention an environmental conservationist focused on wetland ecosystems and climate change mitigation. There's no mention of a law professor or any legal aspects. The answer should be based solely on the context given. Since the context doesn't include anything about a law professor, I need to state that there's no relevant information provided. I should avoid referencing the context directly and not mention the files. Just a straightforward answer that the information isn't available in the given context.\n",
      "</think>\n",
      "\n",
      "The provided context information does not include any details related to a law professor.\n",
      "<think>\n",
      "</think>\n",
      "\n",
      "The provided context information does not include any details related to a law professor."
     ]
    },
    {
     "data": {
      "text/plain": [
       "AgentOutput(response=ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, additional_kwargs={'tool_calls': []}, blocks=[TextBlock(block_type='text', text='<think>\\n</think>\\n\\nThe provided context information does not include any details related to a law professor.')]), tool_calls=[ToolCallResult(tool_name='personas', tool_kwargs={'input': 'law professor'}, tool_id='personas', tool_output=ToolOutput(content='<think>\\nOkay, the user asked about a \"law professor\" and provided some context files. Let me check the context info. The files mention an environmental conservationist focused on wetland ecosystems and climate change mitigation. There\\'s no mention of a law professor or any legal aspects. The answer should be based solely on the context given. Since the context doesn\\'t include anything about a law professor, I need to state that there\\'s no relevant information provided. I should avoid referencing the context directly and not mention the files. Just a straightforward answer that the information isn\\'t available in the given context.\\n</think>\\n\\nThe provided context information does not include any details related to a law professor.', tool_name='personas', raw_input={'input': 'law professor'}, raw_output=Response(response='<think>\\nOkay, the user asked about a \"law professor\" and provided some context files. Let me check the context info. The files mention an environmental conservationist focused on wetland ecosystems and climate change mitigation. There\\'s no mention of a law professor or any legal aspects. The answer should be based solely on the context given. Since the context doesn\\'t include anything about a law professor, I need to state that there\\'s no relevant information provided. I should avoid referencing the context directly and not mention the files. Just a straightforward answer that the information isn\\'t available in the given context.\\n</think>\\n\\nThe provided context information does not include any details related to a law professor.', source_nodes=[NodeWithScore(node=TextNode(id_='249627e8-d685-448a-a587-c8e068def60a', embedding=None, metadata={'file_path': '/Users/karen/Documents/02_AIE Journey/02_Study/05_Agents/01_HF Agents Course/data/persona_100.txt', 'file_name': 'persona_100.txt', 'file_type': 'text/plain', 'file_size': 107, 'creation_date': '2025-05-16', 'last_modified_date': '2025-05-16'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='4d53e000-23e0-49e3-9bbc-fdf10a4e10f7', node_type='4', metadata={'file_path': '/Users/karen/Documents/02_AIE Journey/02_Study/05_Agents/01_HF Agents Course/data/persona_100.txt', 'file_name': 'persona_100.txt', 'file_type': 'text/plain', 'file_size': 107, 'creation_date': '2025-05-16', 'last_modified_date': '2025-05-16'}, hash='552aed281367cfe4997902fb1be815695f711ec2ca317fdb742c4ebc409882e6')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='An environmental conservationist focused on wetland ecosystems and their role in mitigating climate change.', mimetype='text/plain', start_char_idx=0, end_char_idx=107, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.4584185932316251), NodeWithScore(node=TextNode(id_='dd500962-f52b-40b6-bce8-eea7a6806daa', embedding=None, metadata={'file_path': '/Users/karen/Documents/02_AIE Journey/02_Study/05_Agents/01_HF Agents Course/data/persona_100.txt', 'file_name': 'persona_100.txt', 'file_type': 'text/plain', 'file_size': 107, 'creation_date': '2025-05-16', 'last_modified_date': '2025-05-16'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='400dbaaf-7d3c-4258-ac46-17511c4a8570', node_type='4', metadata={'file_path': '/Users/karen/Documents/02_AIE Journey/02_Study/05_Agents/01_HF Agents Course/data/persona_100.txt', 'file_name': 'persona_100.txt', 'file_type': 'text/plain', 'file_size': 107, 'creation_date': '2025-05-16', 'last_modified_date': '2025-05-16'}, hash='552aed281367cfe4997902fb1be815695f711ec2ca317fdb742c4ebc409882e6')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='An environmental conservationist focused on wetland ecosystems and their role in mitigating climate change.', mimetype='text/plain', start_char_idx=0, end_char_idx=107, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.4584185932316251)], metadata={'249627e8-d685-448a-a587-c8e068def60a': {'file_path': '/Users/karen/Documents/02_AIE Journey/02_Study/05_Agents/01_HF Agents Course/data/persona_100.txt', 'file_name': 'persona_100.txt', 'file_type': 'text/plain', 'file_size': 107, 'creation_date': '2025-05-16', 'last_modified_date': '2025-05-16'}, 'dd500962-f52b-40b6-bce8-eea7a6806daa': {'file_path': '/Users/karen/Documents/02_AIE Journey/02_Study/05_Agents/01_HF Agents Course/data/persona_100.txt', 'file_name': 'persona_100.txt', 'file_type': 'text/plain', 'file_size': 107, 'creation_date': '2025-05-16', 'last_modified_date': '2025-05-16'}}), is_error=False), return_direct=False)], raw={'model': 'qwen3:8b', 'created_at': '2025-05-18T13:46:15.888059Z', 'done': True, 'done_reason': 'stop', 'total_duration': 2208586583, 'load_duration': 13804875, 'prompt_eval_count': 334, 'prompt_eval_duration': 1372618750, 'eval_count': 20, 'eval_duration': 813124500, 'message': Message(role='assistant', content='<think>\\n</think>\\n\\nThe provided context information does not include any details related to a law professor.', images=None, tool_calls=None), 'usage': {'prompt_tokens': 334, 'completion_tokens': 20, 'total_tokens': 354}}, current_agent_name='Agent')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run agent\n",
    "handler = query_engine_agent.run(\"Search the database for law professor and return some persona descriptions.\")\n",
    "async for ev in handler.stream_events():\n",
    "    if isinstance(ev, ToolCallResult):\n",
    "        print(\"\")\n",
    "        print(\"Called tool: \", ev.tool_name, ev.tool_kwargs, \"=>\", ev.tool_output)\n",
    "    elif isinstance(ev, AgentStream):  # showing thought process\n",
    "        print(ev.delta, end=\"\", flush=True)\n",
    "\n",
    "resp = await handler\n",
    "resp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4956019c",
   "metadata": {},
   "source": [
    "## Create Multi-Agent Systems\n",
    "We can also create multi-agent systems by passing multiple agents to the `AgentWorkflow` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "85e19947",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent.workflow import AgentWorkflow, ReActAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dcc9c180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tools\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Add two numbers.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "def subtract(a: int, b: int) -> int:\n",
    "    \"\"\"Subtract two numbers.\"\"\"\n",
    "    return a - b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3be129c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create agent configs\n",
    "# NOTE: We can use `FunctionAgent` or `ReActAgent` here. \n",
    "# `FunctionAgent` works for LLMs with a function calling API. \n",
    "# `ReActAgent` works for any LLMs. \n",
    "\n",
    "# Adjust LLM timeout\n",
    "llm = Ollama(model=\"qwen3:8b\", request_timeout=600.0)\n",
    "\n",
    "calculator_agent = ReActAgent(\n",
    "    name=\"calculator\", \n",
    "    description=\"Performs basic arithmetic operations\", \n",
    "    system_prompt=\"You have a calculator assistant. Use your tools for any math operation.\", \n",
    "    tools=[add, subtract], \n",
    "    llm=llm\n",
    ")\n",
    "\n",
    "query_agent = ReActAgent(\n",
    "    name=\"info_lookup\", \n",
    "    description=\"Looks up information about persona descriptions\", \n",
    "    system_prompt=\"Use your tool to query a RAG system to answer information about specific persona.\", \n",
    "    tools=[query_engine_tool], \n",
    "    llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a15077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and run the workflow\n",
    "agent = AgentWorkflow(\n",
    "    agents=[calculator_agent, query_agent], \n",
    "    root_agent=\"calculator\"\n",
    ")\n",
    "\n",
    "# Set up handler\n",
    "handler = agent.run(user_msg=\"Search the database for law professor and return some persona descriptions, then calculate 7 + 3 - 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "eaa65b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, let's tackle this step by step. The user wants two things: first, to search a database for law professor persona descriptions, and then calculate 7 + 3 - 2.\n",
      "\n",
      "Looking at the tools available, there's the 'handoff' tool which can direct to another agent. The 'info_lookup' agent is mentioned, which is for looking up persona descriptions. So I should use the handoff tool to send the search request to the info_lookup agent. The reason would be to get the persona descriptions as part of the task.\n",
      "\n",
      "Once that's done, the calculation part is straightforward. The user then wants to subtract 2 from the sum of 7 and 3. Using the add tool first to add 7 and 3, which gives 10, then subtract 2 using the subtract tool, resulting in 8. But wait, the user wrote 7 + 3 - 2, which can be done in one step. Maybe do 7 + 3 first, then subtract 2. So first action is add with 7 and 3, then subtract the result by 2. \n",
      "\n",
      "But I need to make sure the handoff is done first. Wait, the user's request has two parts. The first part is to search the database, which requires the info_lookup agent. The second part is a math calculation. Since the tools don't include a database search function, I need to hand off to the info_lookup agent for the first part. Then handle the math with the add and subtract tools. \n",
      "\n",
      "So the plan is: handoff to info_lookup for the search, then perform the calculation. But the user might expect both parts to be addressed. However, the tools available don't include a database search, so the handoff is necessary. Then, after getting the persona descriptions (though the tool's response isn't shown here), proceed with the calculation. \n",
      "\n",
      "Wait, but in the current setup, the assistant can't actually perform the database search; it can only hand off. So the first action is to hand off to the info_lookup agent with the reason to search for law professor personas. Then, once that's done, handle the math. \n",
      "\n",
      "So the first step is to use the handoff tool to the info_lookup agent. Then, after that, use add and subtract tools for the calculation. But the user's question is a single request, so the assistant needs to handle both parts. However, since the database search isn't a tool available here, the assistant must hand off that part first. Then proceed with the calculation. \n",
      "\n",
      "Therefore, the initial action is to hand off to the info_lookup agent. Then, once that's done (even though the observation isn't provided here), the assistant can perform the calculation. So the first action is handoff.\n",
      "</think>\n",
      "\n",
      "Thought: The user is asking to search for law professor persona descriptions and perform a calculation. Since I can't directly search a database, I should hand off the info lookup part to the appropriate agent first. Then, I can use the add and subtract tools for the calculation. \n",
      "\n",
      "Action: handoff\n",
      "Action Input: {\"to_agent\": \"info_lookup\", \"reason\": \"Search the database for law professor persona descriptions\"}\n",
      "Called tool:  handoff {'to_agent': 'info_lookup', 'reason': 'Search the database for law professor persona descriptions'} => Agent info_lookup is now handling the request due to the following reason: Search the database for law professor persona descriptions.\n",
      "Please continue with the current request.\n",
      "<think>\n",
      "Okay, the user wants me to search for law professor persona descriptions and then calculate 7 + 3 - 2. Let me break this down.\n",
      "\n",
      "First, the search part. The user mentioned a database, but I don't have a direct tool for that. In the tools provided, there's the 'personas' tool which gives descriptions of various personas. Maybe that's the right tool here. Wait, the user specifically said \"law professor,\" so I should use the personas tool with input \"law professor\" to get the descriptions.\n",
      "\n",
      "Then, the calculation part. The user wants 7 + 3 - 2. The available agents include a calculator, so I can hand off the calculation to the calculator agent. But wait, the user might want the answer directly. Let me check the tools again. The calculator agent can perform basic arithmetic operations, so I can use that. Alternatively, since it's a simple calculation, maybe I can do it myself. But since the user mentioned using tools, maybe it's better to hand it off. However, the initial step was to hand off the info lookup, and now I need to proceed with the calculation. Let me structure the steps properly.\n",
      "\n",
      "So first, use the personas tool with input \"law professor\" to get the descriptions. Then, perform the calculation 7 + 3 - 2. Since the calculator agent is available, I can hand off the calculation to it. But the user might expect the answer after getting the personas. Let me make sure to first retrieve the personas and then calculate.\n",
      "\n",
      "Wait, in the previous step, the user tried to hand off to the info_lookup agent, but the available agents are calculator and others. The personas tool is a tool, not an agent. So perhaps the correct approach is to first use the personas tool to get the descriptions, then use the calculator agent for the math. Let me proceed step by step.\n",
      "</think>\n",
      "\n",
      "Thought: I need to use the personas tool to retrieve law professor descriptions and then calculate the math problem. I'll handle the calculation after obtaining the persona data.\n",
      "Action: personas\n",
      "Action Input: {\"input\": \"law professor\"}\n",
      "Called tool:  personas {'input': 'law professor'} => <think>\n",
      "Okay, the user asked about a \"law professor\" in the context of the provided files. Let me check the context again. The files mention an environmental conservationist focused on wetland ecosystems and their role in mitigating climate change. There's no mention of a law professor or any legal aspects. The answer should be based solely on the context given, and I can't use prior knowledge. Since the context doesn't relate to a law professor, I should state that there's no information provided about that topic. I need to make sure not to reference the context directly and avoid any statements about the context. Just a straightforward answer that the information isn't available here.\n",
      "</think>\n",
      "\n",
      "The provided context does not mention a law professor or any related information.\n",
      "<think>\n",
      "Okay, let's see. The user first asked to search for law professor persona descriptions and then calculate 7 + 3 - 2. I tried to use the personas tool with \"law professor\" as input, but the observation indicated no relevant info was found. Now, I need to handle the calculation part. Since the user mentioned 7 + 3 - 2, I should perform that arithmetic. Let me check if I can do that without a tool. Wait, the tools available include a calculator agent. But the user might expect me to compute it directly. Let me confirm the calculation: 7 + 3 is 10, minus 2 is 8. So the final answer should be 8. Since the personas tool didn't return anything, I should proceed to answer the math part.\n",
      "</think>\n",
      "\n",
      "Thought: I can answer without using any more tools. I'll use the user's language to answer\n",
      "Answer: 8"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AgentOutput(response=ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, additional_kwargs={'tool_calls': []}, blocks=[TextBlock(block_type='text', text='8')]), tool_calls=[ToolCallResult(tool_name='handoff', tool_kwargs={'to_agent': 'info_lookup', 'reason': 'Search the database for law professor persona descriptions'}, tool_id='c99e7ef9-15d3-4743-82a1-6e49b9d24ed7', tool_output=ToolOutput(content='Agent info_lookup is now handling the request due to the following reason: Search the database for law professor persona descriptions.\\nPlease continue with the current request.', tool_name='handoff', raw_input={'args': (), 'kwargs': {'to_agent': 'info_lookup', 'reason': 'Search the database for law professor persona descriptions'}}, raw_output='Agent info_lookup is now handling the request due to the following reason: Search the database for law professor persona descriptions.\\nPlease continue with the current request.', is_error=False), return_direct=True), ToolCallResult(tool_name='personas', tool_kwargs={'input': 'law professor'}, tool_id='fe547562-6cac-431f-a78d-73b6c422bf4a', tool_output=ToolOutput(content='<think>\\nOkay, the user asked about a \"law professor\" in the context of the provided files. Let me check the context again. The files mention an environmental conservationist focused on wetland ecosystems and their role in mitigating climate change. There\\'s no mention of a law professor or any legal aspects. The answer should be based solely on the context given, and I can\\'t use prior knowledge. Since the context doesn\\'t relate to a law professor, I should state that there\\'s no information provided about that topic. I need to make sure not to reference the context directly and avoid any statements about the context. Just a straightforward answer that the information isn\\'t available here.\\n</think>\\n\\nThe provided context does not mention a law professor or any related information.', tool_name='personas', raw_input={'input': 'law professor'}, raw_output=Response(response='<think>\\nOkay, the user asked about a \"law professor\" in the context of the provided files. Let me check the context again. The files mention an environmental conservationist focused on wetland ecosystems and their role in mitigating climate change. There\\'s no mention of a law professor or any legal aspects. The answer should be based solely on the context given, and I can\\'t use prior knowledge. Since the context doesn\\'t relate to a law professor, I should state that there\\'s no information provided about that topic. I need to make sure not to reference the context directly and avoid any statements about the context. Just a straightforward answer that the information isn\\'t available here.\\n</think>\\n\\nThe provided context does not mention a law professor or any related information.', source_nodes=[NodeWithScore(node=TextNode(id_='249627e8-d685-448a-a587-c8e068def60a', embedding=None, metadata={'file_path': '/Users/karen/Documents/02_AIE Journey/02_Study/05_Agents/01_HF Agents Course/data/persona_100.txt', 'file_name': 'persona_100.txt', 'file_type': 'text/plain', 'file_size': 107, 'creation_date': '2025-05-16', 'last_modified_date': '2025-05-16'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='4d53e000-23e0-49e3-9bbc-fdf10a4e10f7', node_type='4', metadata={'file_path': '/Users/karen/Documents/02_AIE Journey/02_Study/05_Agents/01_HF Agents Course/data/persona_100.txt', 'file_name': 'persona_100.txt', 'file_type': 'text/plain', 'file_size': 107, 'creation_date': '2025-05-16', 'last_modified_date': '2025-05-16'}, hash='552aed281367cfe4997902fb1be815695f711ec2ca317fdb742c4ebc409882e6')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='An environmental conservationist focused on wetland ecosystems and their role in mitigating climate change.', mimetype='text/plain', start_char_idx=0, end_char_idx=107, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.4584185932316251), NodeWithScore(node=TextNode(id_='dd500962-f52b-40b6-bce8-eea7a6806daa', embedding=None, metadata={'file_path': '/Users/karen/Documents/02_AIE Journey/02_Study/05_Agents/01_HF Agents Course/data/persona_100.txt', 'file_name': 'persona_100.txt', 'file_type': 'text/plain', 'file_size': 107, 'creation_date': '2025-05-16', 'last_modified_date': '2025-05-16'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='400dbaaf-7d3c-4258-ac46-17511c4a8570', node_type='4', metadata={'file_path': '/Users/karen/Documents/02_AIE Journey/02_Study/05_Agents/01_HF Agents Course/data/persona_100.txt', 'file_name': 'persona_100.txt', 'file_type': 'text/plain', 'file_size': 107, 'creation_date': '2025-05-16', 'last_modified_date': '2025-05-16'}, hash='552aed281367cfe4997902fb1be815695f711ec2ca317fdb742c4ebc409882e6')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='An environmental conservationist focused on wetland ecosystems and their role in mitigating climate change.', mimetype='text/plain', start_char_idx=0, end_char_idx=107, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.4584185932316251)], metadata={'249627e8-d685-448a-a587-c8e068def60a': {'file_path': '/Users/karen/Documents/02_AIE Journey/02_Study/05_Agents/01_HF Agents Course/data/persona_100.txt', 'file_name': 'persona_100.txt', 'file_type': 'text/plain', 'file_size': 107, 'creation_date': '2025-05-16', 'last_modified_date': '2025-05-16'}, 'dd500962-f52b-40b6-bce8-eea7a6806daa': {'file_path': '/Users/karen/Documents/02_AIE Journey/02_Study/05_Agents/01_HF Agents Course/data/persona_100.txt', 'file_name': 'persona_100.txt', 'file_type': 'text/plain', 'file_size': 107, 'creation_date': '2025-05-16', 'last_modified_date': '2025-05-16'}}), is_error=False), return_direct=False)], raw={'model': 'qwen3:8b', 'created_at': '2025-05-18T13:52:48.849389Z', 'done': True, 'done_reason': 'stop', 'total_duration': 13181107166, 'load_duration': 14281416, 'prompt_eval_count': 946, 'prompt_eval_duration': 3993730292, 'eval_count': 196, 'eval_duration': 9153060208, 'message': Message(role='assistant', content='', images=None, tool_calls=None), 'usage': {'prompt_tokens': 946, 'completion_tokens': 196, 'total_tokens': 1142}}, current_agent_name='info_lookup')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the system\n",
    "async for ev in handler.stream_events():\n",
    "    if isinstance(ev, ToolCallResult):\n",
    "        print(\"\")\n",
    "        print(\"Called tool: \", ev.tool_name, ev.tool_kwargs, \"=>\", ev.tool_output)\n",
    "    elif isinstance(ev, AgentStream):  # showing thought process\n",
    "        print(ev.delta, end=\"\", flush=True)\n",
    "\n",
    "resp = await handler\n",
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea7a55e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
